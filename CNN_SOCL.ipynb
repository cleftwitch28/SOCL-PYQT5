{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cleftwitch28/SOCL-PYQT5/blob/main/CNN_SOCL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A5X9GYXUT3l"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image as mp_image\n",
        "import seaborn as sns\n",
        "\n",
        "# Required magic to display matplotlib plots in notebooks\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVuzo5tQUoKZ",
        "outputId": "a4473e65-358f-43df-839b-f0d34d26c380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil', 'Resized images']\n"
          ]
        }
      ],
      "source": [
        "training_folder_name = '/content/drive/MyDrive/Dataset/Train'\n",
        "\n",
        "# All images are 128x128 pixels\n",
        "img_size = (128,128)\n",
        "\n",
        "# The folder contains a subfolder for each class of shape\n",
        "classes = sorted(os.listdir(training_folder_name))\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcs08u1VUrWA",
        "outputId": "6dd7cc55-3f84-452a-ab8f-060318515958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported - ready to use PyTorch 2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il7MvUy2UuQJ"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# function to resize image\n",
        "def resize_image(src_image, size=(128,128), bg_color=\"white\"):\n",
        "    from PIL import Image, ImageOps\n",
        "\n",
        "    # resize the image so the longest dimension matches our target size\n",
        "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
        "\n",
        "    # Create a new square background image\n",
        "    new_image = Image.new(\"RGB\", size, bg_color)\n",
        "\n",
        "    # Paste the resized image into the center of the square background\n",
        "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
        "\n",
        "    # return the resized image\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWk6tS-FUxIY",
        "outputId": "8733b7c6-8e16-4439-b17e-822f62398471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming images...\n",
            "processing folder Alluvial soil\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-89f78d07b612>:8: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  src_image.thumbnail(size, Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing folder Clay soil\n",
            "processing folder Black Soil\n",
            "processing folder Red soil\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "training_folder_name = '/content/drive/MyDrive/Dataset/Train'\n",
        "\n",
        "# New location for the resized images\n",
        "train_folder = '/content/drive/MyDrive/Dataset/Train/Resized images'\n",
        "\n",
        "\n",
        "# Create resized copies of all of the source images\n",
        "size = (128,128)\n",
        "\n",
        "# Create the output folder if it doesn't already exist\n",
        "if os.path.exists(train_folder):\n",
        "    shutil.rmtree(train_folder)\n",
        "\n",
        "# Loop through each subfolder in the input folder\n",
        "print('Transforming images...')\n",
        "for root, folders, files in os.walk(training_folder_name):\n",
        "    for sub_folder in folders:\n",
        "        print('processing folder ' + sub_folder)\n",
        "        # Create a matching subfolder in the output dir\n",
        "        saveFolder = os.path.join(train_folder,sub_folder)\n",
        "        if not os.path.exists(saveFolder):\n",
        "            os.makedirs(saveFolder)\n",
        "        # Loop through the files in the subfolder\n",
        "        file_names = os.listdir(os.path.join(root,sub_folder))\n",
        "        for file_name in file_names:\n",
        "            # Open the file\n",
        "            file_path = os.path.join(root,sub_folder, file_name)\n",
        "            #print(\"reading \" + file_path)\n",
        "            image = Image.open(file_path)\n",
        "            # Create a resized version and save it\n",
        "            resized_image = resize_image(image, size)\n",
        "            saveAs = os.path.join(saveFolder, file_name)\n",
        "            #print(\"writing \" + saveAs)\n",
        "            resized_image.save(saveAs)\n",
        "\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWyDm8VyU0_Y",
        "outputId": "704c8263-077d-4e0f-96f2-8a663708149a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaders ready to read /content/drive/MyDrive/Dataset/Train/Resized images\n"
          ]
        }
      ],
      "source": [
        "def load_dataset(data_path):\n",
        "    import torch\n",
        "    import torchvision\n",
        "    import torchvision.transforms as transforms\n",
        "    # Load all the images\n",
        "    transformation = transforms.Compose([\n",
        "        # Randomly augment the image data\n",
        "            # Random horizontal flip\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "            # Random vertical flip\n",
        "        transforms.RandomVerticalFlip(0.3),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # Load all of the images, transforming them\n",
        "    full_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transformation\n",
        "    )\n",
        "\n",
        "\n",
        "    # Split into training (70% and testing (30%) datasets)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "\n",
        "    # use torch.utils.data.random_split for training/test split\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    # define a loader for the training data we can iterate through in 50-image batches\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=50,\n",
        "        num_workers=0,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # define a loader for the testing data we can iterate through in 50-image batches\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=50,\n",
        "        num_workers=0,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Recall that we have resized the images and saved them into\n",
        "train_folder = '/content/drive/MyDrive/Dataset/Train/Resized images'\n",
        "\n",
        "# Get the iterative dataloaders for test and training data\n",
        "train_loader, test_loader = load_dataset(train_folder)\n",
        "batch_size = train_loader.batch_size\n",
        "print(\"Data loaders ready to read\", train_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_KQff5ufCFW",
        "outputId": "87913fd6-a1f9-44c0-887b-3396bbe4e076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Daw59P_eU5P5",
        "outputId": "682ebc95-c3af-4a37-f631-9765c4f72862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (drop): Dropout2d(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=24576, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create a neural net class\n",
        "class Net(nn.Module):\n",
        "\n",
        "\n",
        "    # Defining the Constructor\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # In the init function, we define each layer we will use in our model\n",
        "\n",
        "        # Our images are RGB, so we have input channels = 3.\n",
        "        # We will apply 12 filters in the first convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # A second convolutional layer takes 12 input channels, and generates 24 outputs\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # We in the end apply max pooling with a kernel size of 2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
        "        self.drop = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
        "        # This means that our feature tensors are now 32 x 32, and we've generated 24 of them\n",
        "\n",
        "        # We need to flatten these in order to feed them to a fully-connected layer\n",
        "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # In the forward function, pass the data through the layers we defined in the init function\n",
        "\n",
        "        # Use a ReLU activation function after layer 1 (convolution 1 and pool)\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "\n",
        "        # Use a ReLU activation function after layer 2\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "\n",
        "        # Select some features to drop to prevent overfitting (only drop during training)\n",
        "        x = F.dropout(self.drop(x), training=self.training)\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(-1, 32 * 32 * 24)\n",
        "        # Feed to fully-connected layer to predict class\n",
        "        x = self.fc(x)\n",
        "        # Return class probabilities via a log_softmax function\n",
        "        return torch.log_softmax(x, dim=1)\n",
        "\n",
        "device = \"cpu\"\n",
        "if (torch.cuda.is_available()):\n",
        "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
        "    device = \"cuda\"\n",
        "\n",
        "# Create an instance of the model class and allocate it to the device\n",
        "model = Net(num_classes=len(classes)).to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkFmBouQU9MB"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    print(\"Epoch:\", epoch)\n",
        "    # Process the images in batches\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Use the CPU or GPU as appropriate\n",
        "        # Recall that GPU is optimized for the operations we are dealing with\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Reset the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Push the data forward through the model layers\n",
        "        output = model(data)\n",
        "\n",
        "        # Get the loss\n",
        "        loss = loss_criteria(output, target)\n",
        "\n",
        "        # Keep a running total\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print metrics so we see some progress\n",
        "        print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
        "\n",
        "    # return average loss for the epoch\n",
        "    avg_loss = train_loss / (batch_idx+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pzzdq7tVAKD"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for data, target in test_loader:\n",
        "            batch_count += 1\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Get the predicted classes for this batch\n",
        "            output = model(data)\n",
        "\n",
        "            # Calculate the loss for this batch\n",
        "            test_loss += loss_criteria(output, target).item()\n",
        "\n",
        "            # Calculate the accuracy for this batch\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "\n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss / batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    # return average loss for the epoch\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d87ngxdzVC7B",
        "outputId": "d5d27f7b-f11d-4a62-900c-94816ad2006f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Epoch: 1\n",
            "\tTraining batch 1 Loss: 1.589127\n",
            "\tTraining batch 2 Loss: 15.630128\n",
            "\tTraining batch 3 Loss: 10.834972\n",
            "\tTraining batch 4 Loss: 16.254648\n",
            "\tTraining batch 5 Loss: 4.688807\n",
            "\tTraining batch 6 Loss: 1.426439\n",
            "\tTraining batch 7 Loss: 1.379161\n",
            "\tTraining batch 8 Loss: 1.533087\n",
            "\tTraining batch 9 Loss: 1.431687\n",
            "\tTraining batch 10 Loss: 1.556376\n",
            "\tTraining batch 11 Loss: 1.588009\n",
            "\tTraining batch 12 Loss: 1.589062\n",
            "\tTraining batch 13 Loss: 1.586092\n",
            "\tTraining batch 14 Loss: 1.581934\n",
            "\tTraining batch 15 Loss: 1.575169\n",
            "\tTraining batch 16 Loss: 1.571583\n",
            "\tTraining batch 17 Loss: 1.568831\n",
            "\tTraining batch 18 Loss: 1.594594\n",
            "Training set: Average loss: 3.832206\n",
            "Validation set: Average loss: 1.563487, Accuracy: 162/366 (44%)\n",
            "\n",
            "Epoch: 2\n",
            "\tTraining batch 1 Loss: 1.562509\n",
            "\tTraining batch 2 Loss: 1.558872\n",
            "\tTraining batch 3 Loss: 1.565464\n",
            "\tTraining batch 4 Loss: 1.537067\n",
            "\tTraining batch 5 Loss: 1.497519\n",
            "\tTraining batch 6 Loss: 1.444552\n",
            "\tTraining batch 7 Loss: 1.283390\n",
            "\tTraining batch 8 Loss: 1.393214\n",
            "\tTraining batch 9 Loss: 1.326296\n",
            "\tTraining batch 10 Loss: 1.258116\n",
            "\tTraining batch 11 Loss: 1.324885\n",
            "\tTraining batch 12 Loss: 1.363046\n",
            "\tTraining batch 13 Loss: 1.358001\n",
            "\tTraining batch 14 Loss: 1.330292\n",
            "\tTraining batch 15 Loss: 1.362058\n",
            "\tTraining batch 16 Loss: 1.238567\n",
            "\tTraining batch 17 Loss: 1.318269\n",
            "\tTraining batch 18 Loss: 1.573773\n",
            "Training set: Average loss: 1.405327\n",
            "Validation set: Average loss: 1.216478, Accuracy: 162/366 (44%)\n",
            "\n",
            "Epoch: 3\n",
            "\tTraining batch 1 Loss: 1.231076\n",
            "\tTraining batch 2 Loss: 1.266796\n",
            "\tTraining batch 3 Loss: 1.207389\n",
            "\tTraining batch 4 Loss: 1.165457\n",
            "\tTraining batch 5 Loss: 1.274387\n",
            "\tTraining batch 6 Loss: 1.174234\n",
            "\tTraining batch 7 Loss: 1.068194\n",
            "\tTraining batch 8 Loss: 1.424609\n",
            "\tTraining batch 9 Loss: 1.370185\n",
            "\tTraining batch 10 Loss: 1.129216\n",
            "\tTraining batch 11 Loss: 1.374047\n",
            "\tTraining batch 12 Loss: 1.208858\n",
            "\tTraining batch 13 Loss: 1.221577\n",
            "\tTraining batch 14 Loss: 1.171171\n",
            "\tTraining batch 15 Loss: 1.110382\n",
            "\tTraining batch 16 Loss: 0.940836\n",
            "\tTraining batch 17 Loss: 1.209825\n",
            "\tTraining batch 18 Loss: 1.535922\n",
            "Training set: Average loss: 1.226898\n",
            "Validation set: Average loss: 1.055969, Accuracy: 175/366 (48%)\n",
            "\n",
            "Epoch: 4\n",
            "\tTraining batch 1 Loss: 1.283180\n",
            "\tTraining batch 2 Loss: 1.249930\n",
            "\tTraining batch 3 Loss: 1.144896\n",
            "\tTraining batch 4 Loss: 1.223589\n",
            "\tTraining batch 5 Loss: 1.206481\n",
            "\tTraining batch 6 Loss: 1.141293\n",
            "\tTraining batch 7 Loss: 1.131240\n",
            "\tTraining batch 8 Loss: 1.158574\n",
            "\tTraining batch 9 Loss: 0.991637\n",
            "\tTraining batch 10 Loss: 1.029277\n",
            "\tTraining batch 11 Loss: 1.138376\n",
            "\tTraining batch 12 Loss: 0.774165\n",
            "\tTraining batch 13 Loss: 0.881571\n",
            "\tTraining batch 14 Loss: 1.101694\n",
            "\tTraining batch 15 Loss: 1.025854\n",
            "\tTraining batch 16 Loss: 0.952858\n",
            "\tTraining batch 17 Loss: 0.970455\n",
            "\tTraining batch 18 Loss: 0.990472\n",
            "Training set: Average loss: 1.077530\n",
            "Validation set: Average loss: 0.893190, Accuracy: 229/366 (63%)\n",
            "\n",
            "Epoch: 5\n",
            "\tTraining batch 1 Loss: 0.899118\n",
            "\tTraining batch 2 Loss: 1.163921\n",
            "\tTraining batch 3 Loss: 0.936366\n",
            "\tTraining batch 4 Loss: 0.885243\n",
            "\tTraining batch 5 Loss: 0.957262\n",
            "\tTraining batch 6 Loss: 1.032482\n",
            "\tTraining batch 7 Loss: 1.195328\n",
            "\tTraining batch 8 Loss: 0.955760\n",
            "\tTraining batch 9 Loss: 1.089223\n",
            "\tTraining batch 10 Loss: 1.051453\n",
            "\tTraining batch 11 Loss: 1.034948\n",
            "\tTraining batch 12 Loss: 1.076178\n",
            "\tTraining batch 13 Loss: 1.187992\n",
            "\tTraining batch 14 Loss: 1.026557\n",
            "\tTraining batch 15 Loss: 1.155169\n",
            "\tTraining batch 16 Loss: 0.882170\n",
            "\tTraining batch 17 Loss: 1.048377\n",
            "\tTraining batch 18 Loss: 0.932005\n",
            "Training set: Average loss: 1.028308\n",
            "Validation set: Average loss: 0.935457, Accuracy: 215/366 (59%)\n",
            "\n",
            "Epoch: 6\n",
            "\tTraining batch 1 Loss: 1.066257\n",
            "\tTraining batch 2 Loss: 1.082306\n",
            "\tTraining batch 3 Loss: 0.983816\n",
            "\tTraining batch 4 Loss: 0.878259\n",
            "\tTraining batch 5 Loss: 0.968453\n",
            "\tTraining batch 6 Loss: 0.908013\n",
            "\tTraining batch 7 Loss: 0.777558\n",
            "\tTraining batch 8 Loss: 1.602632\n",
            "\tTraining batch 9 Loss: 1.177411\n",
            "\tTraining batch 10 Loss: 0.888817\n",
            "\tTraining batch 11 Loss: 1.229084\n",
            "\tTraining batch 12 Loss: 0.761628\n",
            "\tTraining batch 13 Loss: 0.972454\n",
            "\tTraining batch 14 Loss: 0.785349\n",
            "\tTraining batch 15 Loss: 0.805993\n",
            "\tTraining batch 16 Loss: 0.668303\n",
            "\tTraining batch 17 Loss: 0.864533\n",
            "\tTraining batch 18 Loss: 0.781581\n",
            "Training set: Average loss: 0.955691\n",
            "Validation set: Average loss: 0.847757, Accuracy: 249/366 (68%)\n",
            "\n",
            "Epoch: 7\n",
            "\tTraining batch 1 Loss: 0.721551\n",
            "\tTraining batch 2 Loss: 1.006821\n",
            "\tTraining batch 3 Loss: 0.759624\n",
            "\tTraining batch 4 Loss: 0.889188\n",
            "\tTraining batch 5 Loss: 0.946488\n",
            "\tTraining batch 6 Loss: 0.924308\n",
            "\tTraining batch 7 Loss: 0.732637\n",
            "\tTraining batch 8 Loss: 0.946467\n",
            "\tTraining batch 9 Loss: 1.023538\n",
            "\tTraining batch 10 Loss: 0.752993\n",
            "\tTraining batch 11 Loss: 0.954276\n",
            "\tTraining batch 12 Loss: 0.698474\n",
            "\tTraining batch 13 Loss: 0.835535\n",
            "\tTraining batch 14 Loss: 0.840530\n",
            "\tTraining batch 15 Loss: 0.714732\n",
            "\tTraining batch 16 Loss: 0.602344\n",
            "\tTraining batch 17 Loss: 0.824871\n",
            "\tTraining batch 18 Loss: 1.067907\n",
            "Training set: Average loss: 0.846794\n",
            "Validation set: Average loss: 0.793273, Accuracy: 249/366 (68%)\n",
            "\n",
            "Epoch: 8\n",
            "\tTraining batch 1 Loss: 0.695871\n",
            "\tTraining batch 2 Loss: 0.900159\n",
            "\tTraining batch 3 Loss: 0.623118\n",
            "\tTraining batch 4 Loss: 0.778446\n",
            "\tTraining batch 5 Loss: 0.726278\n",
            "\tTraining batch 6 Loss: 0.678826\n",
            "\tTraining batch 7 Loss: 0.802757\n",
            "\tTraining batch 8 Loss: 0.778411\n",
            "\tTraining batch 9 Loss: 0.725086\n",
            "\tTraining batch 10 Loss: 0.614685\n",
            "\tTraining batch 11 Loss: 0.964348\n",
            "\tTraining batch 12 Loss: 0.902853\n",
            "\tTraining batch 13 Loss: 1.100401\n",
            "\tTraining batch 14 Loss: 0.625699\n",
            "\tTraining batch 15 Loss: 0.879259\n",
            "\tTraining batch 16 Loss: 0.603643\n",
            "\tTraining batch 17 Loss: 0.688846\n",
            "\tTraining batch 18 Loss: 0.744731\n",
            "Training set: Average loss: 0.768523\n",
            "Validation set: Average loss: 0.834862, Accuracy: 250/366 (68%)\n",
            "\n",
            "Epoch: 9\n",
            "\tTraining batch 1 Loss: 0.620693\n",
            "\tTraining batch 2 Loss: 1.133598\n",
            "\tTraining batch 3 Loss: 0.825664\n",
            "\tTraining batch 4 Loss: 0.799848\n",
            "\tTraining batch 5 Loss: 0.757703\n",
            "\tTraining batch 6 Loss: 0.758427\n",
            "\tTraining batch 7 Loss: 0.630858\n",
            "\tTraining batch 8 Loss: 1.031785\n",
            "\tTraining batch 9 Loss: 0.731387\n",
            "\tTraining batch 10 Loss: 0.784437\n",
            "\tTraining batch 11 Loss: 0.933325\n",
            "\tTraining batch 12 Loss: 0.698757\n",
            "\tTraining batch 13 Loss: 0.762702\n",
            "\tTraining batch 14 Loss: 0.776430\n",
            "\tTraining batch 15 Loss: 0.585998\n",
            "\tTraining batch 16 Loss: 0.616379\n",
            "\tTraining batch 17 Loss: 0.816874\n",
            "\tTraining batch 18 Loss: 1.182285\n",
            "Training set: Average loss: 0.802619\n",
            "Validation set: Average loss: 0.656294, Accuracy: 263/366 (72%)\n",
            "\n",
            "Epoch: 10\n",
            "\tTraining batch 1 Loss: 0.693726\n",
            "\tTraining batch 2 Loss: 0.816395\n",
            "\tTraining batch 3 Loss: 0.520752\n",
            "\tTraining batch 4 Loss: 0.923365\n",
            "\tTraining batch 5 Loss: 0.859711\n",
            "\tTraining batch 6 Loss: 0.726882\n",
            "\tTraining batch 7 Loss: 0.899307\n",
            "\tTraining batch 8 Loss: 1.036988\n",
            "\tTraining batch 9 Loss: 0.862167\n",
            "\tTraining batch 10 Loss: 0.738103\n",
            "\tTraining batch 11 Loss: 0.722098\n",
            "\tTraining batch 12 Loss: 0.680784\n",
            "\tTraining batch 13 Loss: 0.740471\n",
            "\tTraining batch 14 Loss: 0.593840\n",
            "\tTraining batch 15 Loss: 0.549393\n",
            "\tTraining batch 16 Loss: 0.636031\n",
            "\tTraining batch 17 Loss: 0.767764\n",
            "\tTraining batch 18 Loss: 1.602049\n",
            "Training set: Average loss: 0.798324\n",
            "Validation set: Average loss: 0.643292, Accuracy: 276/366 (75%)\n",
            "\n",
            "Epoch: 11\n",
            "\tTraining batch 1 Loss: 0.636377\n",
            "\tTraining batch 2 Loss: 0.808247\n",
            "\tTraining batch 3 Loss: 0.412664\n",
            "\tTraining batch 4 Loss: 0.784945\n",
            "\tTraining batch 5 Loss: 0.807833\n",
            "\tTraining batch 6 Loss: 0.716194\n",
            "\tTraining batch 7 Loss: 0.599800\n",
            "\tTraining batch 8 Loss: 0.978764\n",
            "\tTraining batch 9 Loss: 0.895148\n",
            "\tTraining batch 10 Loss: 0.598813\n",
            "\tTraining batch 11 Loss: 0.921540\n",
            "\tTraining batch 12 Loss: 0.665572\n",
            "\tTraining batch 13 Loss: 0.761690\n",
            "\tTraining batch 14 Loss: 0.761432\n",
            "\tTraining batch 15 Loss: 0.425032\n",
            "\tTraining batch 16 Loss: 0.550377\n",
            "\tTraining batch 17 Loss: 0.746743\n",
            "\tTraining batch 18 Loss: 0.531693\n",
            "Training set: Average loss: 0.700159\n",
            "Validation set: Average loss: 0.589318, Accuracy: 285/366 (78%)\n",
            "\n",
            "Epoch: 12\n",
            "\tTraining batch 1 Loss: 0.615187\n",
            "\tTraining batch 2 Loss: 0.741086\n",
            "\tTraining batch 3 Loss: 0.556110\n",
            "\tTraining batch 4 Loss: 0.673252\n",
            "\tTraining batch 5 Loss: 0.568843\n",
            "\tTraining batch 6 Loss: 0.646053\n",
            "\tTraining batch 7 Loss: 0.688500\n",
            "\tTraining batch 8 Loss: 0.652241\n",
            "\tTraining batch 9 Loss: 0.687557\n",
            "\tTraining batch 10 Loss: 0.584963\n",
            "\tTraining batch 11 Loss: 0.614270\n",
            "\tTraining batch 12 Loss: 0.548386\n",
            "\tTraining batch 13 Loss: 0.664201\n",
            "\tTraining batch 14 Loss: 0.658080\n",
            "\tTraining batch 15 Loss: 0.494353\n",
            "\tTraining batch 16 Loss: 0.484691\n",
            "\tTraining batch 17 Loss: 0.654106\n",
            "\tTraining batch 18 Loss: 0.458042\n",
            "Training set: Average loss: 0.610551\n",
            "Validation set: Average loss: 0.542233, Accuracy: 292/366 (80%)\n",
            "\n",
            "Epoch: 13\n",
            "\tTraining batch 1 Loss: 0.458665\n",
            "\tTraining batch 2 Loss: 0.658932\n",
            "\tTraining batch 3 Loss: 0.542899\n",
            "\tTraining batch 4 Loss: 0.660516\n",
            "\tTraining batch 5 Loss: 0.528058\n",
            "\tTraining batch 6 Loss: 0.596935\n",
            "\tTraining batch 7 Loss: 0.660654\n",
            "\tTraining batch 8 Loss: 0.575257\n",
            "\tTraining batch 9 Loss: 0.653523\n",
            "\tTraining batch 10 Loss: 0.553022\n",
            "\tTraining batch 11 Loss: 0.734024\n",
            "\tTraining batch 12 Loss: 0.573285\n",
            "\tTraining batch 13 Loss: 0.459093\n",
            "\tTraining batch 14 Loss: 0.869337\n",
            "\tTraining batch 15 Loss: 0.438582\n",
            "\tTraining batch 16 Loss: 0.605935\n",
            "\tTraining batch 17 Loss: 0.364143\n",
            "\tTraining batch 18 Loss: 1.300930\n",
            "Training set: Average loss: 0.624099\n",
            "Validation set: Average loss: 0.523398, Accuracy: 296/366 (81%)\n",
            "\n",
            "Epoch: 14\n",
            "\tTraining batch 1 Loss: 0.512089\n",
            "\tTraining batch 2 Loss: 0.711485\n",
            "\tTraining batch 3 Loss: 0.388573\n",
            "\tTraining batch 4 Loss: 0.530096\n",
            "\tTraining batch 5 Loss: 0.567877\n",
            "\tTraining batch 6 Loss: 0.526039\n",
            "\tTraining batch 7 Loss: 0.593395\n",
            "\tTraining batch 8 Loss: 0.412468\n",
            "\tTraining batch 9 Loss: 0.561498\n",
            "\tTraining batch 10 Loss: 0.454578\n",
            "\tTraining batch 11 Loss: 0.836120\n",
            "\tTraining batch 12 Loss: 0.581381\n",
            "\tTraining batch 13 Loss: 0.551303\n",
            "\tTraining batch 14 Loss: 0.449335\n",
            "\tTraining batch 15 Loss: 0.532529\n",
            "\tTraining batch 16 Loss: 0.405807\n",
            "\tTraining batch 17 Loss: 0.483489\n",
            "\tTraining batch 18 Loss: 1.296289\n",
            "Training set: Average loss: 0.577464\n",
            "Validation set: Average loss: 0.470163, Accuracy: 305/366 (83%)\n",
            "\n",
            "Epoch: 15\n",
            "\tTraining batch 1 Loss: 0.598649\n",
            "\tTraining batch 2 Loss: 0.538051\n",
            "\tTraining batch 3 Loss: 0.444079\n",
            "\tTraining batch 4 Loss: 0.510179\n",
            "\tTraining batch 5 Loss: 0.417111\n",
            "\tTraining batch 6 Loss: 0.526715\n",
            "\tTraining batch 7 Loss: 0.583002\n",
            "\tTraining batch 8 Loss: 0.480068\n",
            "\tTraining batch 9 Loss: 0.581191\n",
            "\tTraining batch 10 Loss: 0.403859\n",
            "\tTraining batch 11 Loss: 0.563520\n",
            "\tTraining batch 12 Loss: 0.609998\n",
            "\tTraining batch 13 Loss: 0.365030\n",
            "\tTraining batch 14 Loss: 0.513418\n",
            "\tTraining batch 15 Loss: 0.745999\n",
            "\tTraining batch 16 Loss: 0.301028\n",
            "\tTraining batch 17 Loss: 0.469813\n",
            "\tTraining batch 18 Loss: 0.367960\n",
            "Training set: Average loss: 0.501093\n",
            "Validation set: Average loss: 0.391681, Accuracy: 312/366 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "\tTraining batch 1 Loss: 0.395850\n",
            "\tTraining batch 2 Loss: 0.552116\n",
            "\tTraining batch 3 Loss: 0.353096\n",
            "\tTraining batch 4 Loss: 0.456779\n",
            "\tTraining batch 5 Loss: 0.518424\n",
            "\tTraining batch 6 Loss: 0.407981\n",
            "\tTraining batch 7 Loss: 0.372381\n",
            "\tTraining batch 8 Loss: 0.517530\n",
            "\tTraining batch 9 Loss: 0.641993\n",
            "\tTraining batch 10 Loss: 0.286171\n",
            "\tTraining batch 11 Loss: 0.502200\n",
            "\tTraining batch 12 Loss: 0.413594\n",
            "\tTraining batch 13 Loss: 0.444325\n",
            "\tTraining batch 14 Loss: 0.504685\n",
            "\tTraining batch 15 Loss: 0.292838\n",
            "\tTraining batch 16 Loss: 0.399465\n",
            "\tTraining batch 17 Loss: 0.468736\n",
            "\tTraining batch 18 Loss: 0.941111\n",
            "Training set: Average loss: 0.470515\n",
            "Validation set: Average loss: 0.416674, Accuracy: 306/366 (84%)\n",
            "\n",
            "Epoch: 17\n",
            "\tTraining batch 1 Loss: 0.539562\n",
            "\tTraining batch 2 Loss: 0.535875\n",
            "\tTraining batch 3 Loss: 0.391756\n",
            "\tTraining batch 4 Loss: 0.589626\n",
            "\tTraining batch 5 Loss: 0.579886\n",
            "\tTraining batch 6 Loss: 0.420109\n",
            "\tTraining batch 7 Loss: 0.495252\n",
            "\tTraining batch 8 Loss: 0.425285\n",
            "\tTraining batch 9 Loss: 0.532484\n",
            "\tTraining batch 10 Loss: 0.471031\n",
            "\tTraining batch 11 Loss: 0.759332\n",
            "\tTraining batch 12 Loss: 0.547005\n",
            "\tTraining batch 13 Loss: 0.582120\n",
            "\tTraining batch 14 Loss: 0.480032\n",
            "\tTraining batch 15 Loss: 0.336764\n",
            "\tTraining batch 16 Loss: 0.342952\n",
            "\tTraining batch 17 Loss: 0.312278\n",
            "\tTraining batch 18 Loss: 0.945959\n",
            "Training set: Average loss: 0.515962\n",
            "Validation set: Average loss: 0.451491, Accuracy: 312/366 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "\tTraining batch 1 Loss: 0.389839\n",
            "\tTraining batch 2 Loss: 0.897788\n",
            "\tTraining batch 3 Loss: 0.280334\n",
            "\tTraining batch 4 Loss: 0.601288\n",
            "\tTraining batch 5 Loss: 0.404527\n",
            "\tTraining batch 6 Loss: 0.488337\n",
            "\tTraining batch 7 Loss: 0.554151\n",
            "\tTraining batch 8 Loss: 0.378994\n",
            "\tTraining batch 9 Loss: 0.687957\n",
            "\tTraining batch 10 Loss: 0.456215\n",
            "\tTraining batch 11 Loss: 0.601302\n",
            "\tTraining batch 12 Loss: 0.397896\n",
            "\tTraining batch 13 Loss: 0.385098\n",
            "\tTraining batch 14 Loss: 0.495840\n",
            "\tTraining batch 15 Loss: 0.419736\n",
            "\tTraining batch 16 Loss: 0.409565\n",
            "\tTraining batch 17 Loss: 0.375120\n",
            "\tTraining batch 18 Loss: 1.043082\n",
            "Training set: Average loss: 0.514837\n",
            "Validation set: Average loss: 0.447049, Accuracy: 302/366 (83%)\n",
            "\n",
            "Epoch: 19\n",
            "\tTraining batch 1 Loss: 0.495395\n",
            "\tTraining batch 2 Loss: 0.634657\n",
            "\tTraining batch 3 Loss: 0.234097\n",
            "\tTraining batch 4 Loss: 0.567213\n",
            "\tTraining batch 5 Loss: 0.525629\n",
            "\tTraining batch 6 Loss: 0.589452\n",
            "\tTraining batch 7 Loss: 0.491760\n",
            "\tTraining batch 8 Loss: 0.452782\n",
            "\tTraining batch 9 Loss: 0.539567\n",
            "\tTraining batch 10 Loss: 0.408586\n",
            "\tTraining batch 11 Loss: 0.703577\n",
            "\tTraining batch 12 Loss: 0.468480\n",
            "\tTraining batch 13 Loss: 0.527167\n",
            "\tTraining batch 14 Loss: 0.439549\n",
            "\tTraining batch 15 Loss: 0.401147\n",
            "\tTraining batch 16 Loss: 0.486049\n",
            "\tTraining batch 17 Loss: 0.441421\n",
            "\tTraining batch 18 Loss: 1.385533\n",
            "Training set: Average loss: 0.544003\n",
            "Validation set: Average loss: 0.423770, Accuracy: 306/366 (84%)\n",
            "\n",
            "Epoch: 20\n",
            "\tTraining batch 1 Loss: 0.510389\n",
            "\tTraining batch 2 Loss: 0.414808\n",
            "\tTraining batch 3 Loss: 0.234693\n",
            "\tTraining batch 4 Loss: 0.609483\n",
            "\tTraining batch 5 Loss: 0.592957\n",
            "\tTraining batch 6 Loss: 0.504962\n",
            "\tTraining batch 7 Loss: 0.712329\n",
            "\tTraining batch 8 Loss: 0.393610\n",
            "\tTraining batch 9 Loss: 0.550594\n",
            "\tTraining batch 10 Loss: 0.476226\n",
            "\tTraining batch 11 Loss: 0.638972\n",
            "\tTraining batch 12 Loss: 0.484137\n",
            "\tTraining batch 13 Loss: 0.434263\n",
            "\tTraining batch 14 Loss: 0.304094\n",
            "\tTraining batch 15 Loss: 0.289014\n",
            "\tTraining batch 16 Loss: 0.272381\n",
            "\tTraining batch 17 Loss: 0.547944\n",
            "\tTraining batch 18 Loss: 1.334694\n",
            "Training set: Average loss: 0.516975\n",
            "Validation set: Average loss: 0.373074, Accuracy: 308/366 (84%)\n",
            "\n",
            "Epoch: 21\n",
            "\tTraining batch 1 Loss: 0.339732\n",
            "\tTraining batch 2 Loss: 0.570664\n",
            "\tTraining batch 3 Loss: 0.261332\n",
            "\tTraining batch 4 Loss: 0.551143\n",
            "\tTraining batch 5 Loss: 0.449933\n",
            "\tTraining batch 6 Loss: 0.410507\n",
            "\tTraining batch 7 Loss: 0.472436\n",
            "\tTraining batch 8 Loss: 0.468634\n",
            "\tTraining batch 9 Loss: 0.488647\n",
            "\tTraining batch 10 Loss: 0.446480\n",
            "\tTraining batch 11 Loss: 0.384201\n",
            "\tTraining batch 12 Loss: 0.312654\n",
            "\tTraining batch 13 Loss: 0.417696\n",
            "\tTraining batch 14 Loss: 0.518775\n",
            "\tTraining batch 15 Loss: 0.389888\n",
            "\tTraining batch 16 Loss: 0.262345\n",
            "\tTraining batch 17 Loss: 0.426583\n",
            "\tTraining batch 18 Loss: 0.342039\n",
            "Training set: Average loss: 0.417427\n",
            "Validation set: Average loss: 0.480078, Accuracy: 312/366 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "\tTraining batch 1 Loss: 0.470383\n",
            "\tTraining batch 2 Loss: 0.398191\n",
            "\tTraining batch 3 Loss: 0.230961\n",
            "\tTraining batch 4 Loss: 0.415728\n",
            "\tTraining batch 5 Loss: 0.292645\n",
            "\tTraining batch 6 Loss: 0.444831\n",
            "\tTraining batch 7 Loss: 0.473833\n",
            "\tTraining batch 8 Loss: 0.597301\n",
            "\tTraining batch 9 Loss: 0.539213\n",
            "\tTraining batch 10 Loss: 0.489692\n",
            "\tTraining batch 11 Loss: 0.480292\n",
            "\tTraining batch 12 Loss: 0.281747\n",
            "\tTraining batch 13 Loss: 0.519629\n",
            "\tTraining batch 14 Loss: 0.405259\n",
            "\tTraining batch 15 Loss: 0.328497\n",
            "\tTraining batch 16 Loss: 0.329348\n",
            "\tTraining batch 17 Loss: 0.414779\n",
            "\tTraining batch 18 Loss: 0.573107\n",
            "Training set: Average loss: 0.426969\n",
            "Validation set: Average loss: 0.392730, Accuracy: 315/366 (86%)\n",
            "\n",
            "Epoch: 23\n",
            "\tTraining batch 1 Loss: 0.170541\n",
            "\tTraining batch 2 Loss: 0.573791\n",
            "\tTraining batch 3 Loss: 0.294188\n",
            "\tTraining batch 4 Loss: 0.877747\n",
            "\tTraining batch 5 Loss: 0.524029\n",
            "\tTraining batch 6 Loss: 0.418952\n",
            "\tTraining batch 7 Loss: 0.468563\n",
            "\tTraining batch 8 Loss: 0.459724\n",
            "\tTraining batch 9 Loss: 0.466231\n",
            "\tTraining batch 10 Loss: 0.342872\n",
            "\tTraining batch 11 Loss: 0.474973\n",
            "\tTraining batch 12 Loss: 0.346846\n",
            "\tTraining batch 13 Loss: 0.427674\n",
            "\tTraining batch 14 Loss: 0.336993\n",
            "\tTraining batch 15 Loss: 0.311591\n",
            "\tTraining batch 16 Loss: 0.350498\n",
            "\tTraining batch 17 Loss: 0.466586\n",
            "\tTraining batch 18 Loss: 0.822240\n",
            "Training set: Average loss: 0.451891\n",
            "Validation set: Average loss: 0.483779, Accuracy: 314/366 (86%)\n",
            "\n",
            "Epoch: 24\n",
            "\tTraining batch 1 Loss: 0.702095\n",
            "\tTraining batch 2 Loss: 0.499250\n",
            "\tTraining batch 3 Loss: 0.234733\n",
            "\tTraining batch 4 Loss: 0.507172\n",
            "\tTraining batch 5 Loss: 0.621612\n",
            "\tTraining batch 6 Loss: 0.538437\n",
            "\tTraining batch 7 Loss: 0.565277\n",
            "\tTraining batch 8 Loss: 0.450869\n",
            "\tTraining batch 9 Loss: 0.752070\n",
            "\tTraining batch 10 Loss: 0.365103\n",
            "\tTraining batch 11 Loss: 0.552642\n",
            "\tTraining batch 12 Loss: 0.418016\n",
            "\tTraining batch 13 Loss: 0.520740\n",
            "\tTraining batch 14 Loss: 0.345190\n",
            "\tTraining batch 15 Loss: 0.259438\n",
            "\tTraining batch 16 Loss: 0.363934\n",
            "\tTraining batch 17 Loss: 0.350373\n",
            "\tTraining batch 18 Loss: 0.668813\n",
            "Training set: Average loss: 0.484209\n",
            "Validation set: Average loss: 0.447996, Accuracy: 307/366 (84%)\n",
            "\n",
            "Epoch: 25\n",
            "\tTraining batch 1 Loss: 0.410899\n",
            "\tTraining batch 2 Loss: 0.420493\n",
            "\tTraining batch 3 Loss: 0.349113\n",
            "\tTraining batch 4 Loss: 0.460806\n",
            "\tTraining batch 5 Loss: 0.602521\n",
            "\tTraining batch 6 Loss: 0.384249\n",
            "\tTraining batch 7 Loss: 0.312164\n",
            "\tTraining batch 8 Loss: 0.390985\n",
            "\tTraining batch 9 Loss: 0.467770\n",
            "\tTraining batch 10 Loss: 0.496563\n",
            "\tTraining batch 11 Loss: 0.502194\n",
            "\tTraining batch 12 Loss: 0.338165\n",
            "\tTraining batch 13 Loss: 0.369945\n",
            "\tTraining batch 14 Loss: 0.502602\n",
            "\tTraining batch 15 Loss: 0.216246\n",
            "\tTraining batch 16 Loss: 0.222011\n",
            "\tTraining batch 17 Loss: 0.406174\n",
            "\tTraining batch 18 Loss: 0.454997\n",
            "Training set: Average loss: 0.405994\n",
            "Validation set: Average loss: 0.468373, Accuracy: 308/366 (84%)\n",
            "\n",
            "Epoch: 26\n",
            "\tTraining batch 1 Loss: 0.562310\n",
            "\tTraining batch 2 Loss: 0.579497\n",
            "\tTraining batch 3 Loss: 0.202866\n",
            "\tTraining batch 4 Loss: 0.577492\n",
            "\tTraining batch 5 Loss: 0.434124\n",
            "\tTraining batch 6 Loss: 0.440822\n",
            "\tTraining batch 7 Loss: 0.316137\n",
            "\tTraining batch 8 Loss: 0.876745\n",
            "\tTraining batch 9 Loss: 0.575277\n",
            "\tTraining batch 10 Loss: 0.251699\n",
            "\tTraining batch 11 Loss: 0.736306\n",
            "\tTraining batch 12 Loss: 0.125295\n",
            "\tTraining batch 13 Loss: 0.484347\n",
            "\tTraining batch 14 Loss: 0.596350\n",
            "\tTraining batch 15 Loss: 0.309952\n",
            "\tTraining batch 16 Loss: 0.352237\n",
            "\tTraining batch 17 Loss: 0.335731\n",
            "\tTraining batch 18 Loss: 0.072358\n",
            "Training set: Average loss: 0.434975\n",
            "Validation set: Average loss: 0.546470, Accuracy: 302/366 (83%)\n",
            "\n",
            "Epoch: 27\n",
            "\tTraining batch 1 Loss: 0.299289\n",
            "\tTraining batch 2 Loss: 0.640822\n",
            "\tTraining batch 3 Loss: 0.307343\n",
            "\tTraining batch 4 Loss: 0.463620\n",
            "\tTraining batch 5 Loss: 0.510029\n",
            "\tTraining batch 6 Loss: 0.556165\n",
            "\tTraining batch 7 Loss: 0.217546\n",
            "\tTraining batch 8 Loss: 0.362711\n",
            "\tTraining batch 9 Loss: 0.767506\n",
            "\tTraining batch 10 Loss: 0.476929\n",
            "\tTraining batch 11 Loss: 0.492477\n",
            "\tTraining batch 12 Loss: 0.283741\n",
            "\tTraining batch 13 Loss: 0.285329\n",
            "\tTraining batch 14 Loss: 0.378839\n",
            "\tTraining batch 15 Loss: 0.402800\n",
            "\tTraining batch 16 Loss: 0.476680\n",
            "\tTraining batch 17 Loss: 0.231145\n",
            "\tTraining batch 18 Loss: 0.915845\n",
            "Training set: Average loss: 0.448268\n",
            "Validation set: Average loss: 0.351160, Accuracy: 316/366 (86%)\n",
            "\n",
            "Epoch: 28\n",
            "\tTraining batch 1 Loss: 0.284959\n",
            "\tTraining batch 2 Loss: 0.400080\n",
            "\tTraining batch 3 Loss: 0.349828\n",
            "\tTraining batch 4 Loss: 0.638600\n",
            "\tTraining batch 5 Loss: 0.397234\n",
            "\tTraining batch 6 Loss: 0.482652\n",
            "\tTraining batch 7 Loss: 0.596364\n",
            "\tTraining batch 8 Loss: 0.467357\n",
            "\tTraining batch 9 Loss: 0.451483\n",
            "\tTraining batch 10 Loss: 0.517988\n",
            "\tTraining batch 11 Loss: 0.625135\n",
            "\tTraining batch 12 Loss: 0.324142\n",
            "\tTraining batch 13 Loss: 0.306348\n",
            "\tTraining batch 14 Loss: 0.415368\n",
            "\tTraining batch 15 Loss: 0.306679\n",
            "\tTraining batch 16 Loss: 0.370846\n",
            "\tTraining batch 17 Loss: 0.580473\n",
            "\tTraining batch 18 Loss: 0.457597\n",
            "Training set: Average loss: 0.442952\n",
            "Validation set: Average loss: 0.409619, Accuracy: 311/366 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "\tTraining batch 1 Loss: 0.385992\n",
            "\tTraining batch 2 Loss: 0.371997\n",
            "\tTraining batch 3 Loss: 0.560219\n",
            "\tTraining batch 4 Loss: 0.337302\n",
            "\tTraining batch 5 Loss: 0.518637\n",
            "\tTraining batch 6 Loss: 0.477253\n",
            "\tTraining batch 7 Loss: 0.647487\n",
            "\tTraining batch 8 Loss: 0.332093\n",
            "\tTraining batch 9 Loss: 0.607390\n",
            "\tTraining batch 10 Loss: 0.278854\n",
            "\tTraining batch 11 Loss: 0.682521\n",
            "\tTraining batch 12 Loss: 0.404342\n",
            "\tTraining batch 13 Loss: 0.335696\n",
            "\tTraining batch 14 Loss: 0.264140\n",
            "\tTraining batch 15 Loss: 0.365169\n",
            "\tTraining batch 16 Loss: 0.361670\n",
            "\tTraining batch 17 Loss: 0.376743\n",
            "\tTraining batch 18 Loss: 0.179144\n",
            "Training set: Average loss: 0.415925\n",
            "Validation set: Average loss: 0.523776, Accuracy: 306/366 (84%)\n",
            "\n",
            "Epoch: 30\n",
            "\tTraining batch 1 Loss: 0.491976\n",
            "\tTraining batch 2 Loss: 0.638260\n",
            "\tTraining batch 3 Loss: 0.145288\n",
            "\tTraining batch 4 Loss: 0.623165\n",
            "\tTraining batch 5 Loss: 0.634837\n",
            "\tTraining batch 6 Loss: 0.454917\n",
            "\tTraining batch 7 Loss: 0.668859\n",
            "\tTraining batch 8 Loss: 0.466940\n",
            "\tTraining batch 9 Loss: 0.538083\n",
            "\tTraining batch 10 Loss: 0.484047\n",
            "\tTraining batch 11 Loss: 0.531960\n",
            "\tTraining batch 12 Loss: 0.331551\n",
            "\tTraining batch 13 Loss: 0.325910\n",
            "\tTraining batch 14 Loss: 0.383647\n",
            "\tTraining batch 15 Loss: 0.268724\n",
            "\tTraining batch 16 Loss: 0.399030\n",
            "\tTraining batch 17 Loss: 0.421557\n",
            "\tTraining batch 18 Loss: 0.479335\n",
            "Training set: Average loss: 0.460449\n",
            "Validation set: Average loss: 0.447969, Accuracy: 310/366 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "\tTraining batch 1 Loss: 0.409525\n",
            "\tTraining batch 2 Loss: 0.520007\n",
            "\tTraining batch 3 Loss: 0.435171\n",
            "\tTraining batch 4 Loss: 0.374218\n",
            "\tTraining batch 5 Loss: 0.546971\n",
            "\tTraining batch 6 Loss: 0.493830\n",
            "\tTraining batch 7 Loss: 0.427217\n",
            "\tTraining batch 8 Loss: 0.392609\n",
            "\tTraining batch 9 Loss: 0.606808\n",
            "\tTraining batch 10 Loss: 0.327673\n",
            "\tTraining batch 11 Loss: 0.484046\n",
            "\tTraining batch 12 Loss: 0.344273\n",
            "\tTraining batch 13 Loss: 0.505305\n",
            "\tTraining batch 14 Loss: 0.889259\n",
            "\tTraining batch 15 Loss: 0.203412\n",
            "\tTraining batch 16 Loss: 0.276653\n",
            "\tTraining batch 17 Loss: 0.367676\n",
            "\tTraining batch 18 Loss: 0.227789\n",
            "Training set: Average loss: 0.435136\n",
            "Validation set: Average loss: 0.379616, Accuracy: 318/366 (87%)\n",
            "\n",
            "Epoch: 32\n",
            "\tTraining batch 1 Loss: 0.286084\n",
            "\tTraining batch 2 Loss: 0.228582\n",
            "\tTraining batch 3 Loss: 0.166286\n",
            "\tTraining batch 4 Loss: 0.266640\n",
            "\tTraining batch 5 Loss: 0.380439\n",
            "\tTraining batch 6 Loss: 0.438900\n",
            "\tTraining batch 7 Loss: 0.329563\n",
            "\tTraining batch 8 Loss: 0.308802\n",
            "\tTraining batch 9 Loss: 0.525961\n",
            "\tTraining batch 10 Loss: 0.165665\n",
            "\tTraining batch 11 Loss: 0.517546\n",
            "\tTraining batch 12 Loss: 0.239597\n",
            "\tTraining batch 13 Loss: 0.389174\n",
            "\tTraining batch 14 Loss: 0.293803\n",
            "\tTraining batch 15 Loss: 0.340486\n",
            "\tTraining batch 16 Loss: 0.361569\n",
            "\tTraining batch 17 Loss: 0.297400\n",
            "\tTraining batch 18 Loss: 0.005298\n",
            "Training set: Average loss: 0.307877\n",
            "Validation set: Average loss: 0.383287, Accuracy: 320/366 (87%)\n",
            "\n",
            "Epoch: 33\n",
            "\tTraining batch 1 Loss: 0.261835\n",
            "\tTraining batch 2 Loss: 0.212212\n",
            "\tTraining batch 3 Loss: 0.226305\n",
            "\tTraining batch 4 Loss: 0.381183\n",
            "\tTraining batch 5 Loss: 0.403460\n",
            "\tTraining batch 6 Loss: 0.330002\n",
            "\tTraining batch 7 Loss: 0.223021\n",
            "\tTraining batch 8 Loss: 0.206230\n",
            "\tTraining batch 9 Loss: 0.699475\n",
            "\tTraining batch 10 Loss: 0.205302\n",
            "\tTraining batch 11 Loss: 0.634951\n",
            "\tTraining batch 12 Loss: 0.235672\n",
            "\tTraining batch 13 Loss: 0.521646\n",
            "\tTraining batch 14 Loss: 0.173997\n",
            "\tTraining batch 15 Loss: 0.210011\n",
            "\tTraining batch 16 Loss: 0.213834\n",
            "\tTraining batch 17 Loss: 0.329543\n",
            "\tTraining batch 18 Loss: 0.601024\n",
            "Training set: Average loss: 0.337206\n",
            "Validation set: Average loss: 0.431815, Accuracy: 314/366 (86%)\n",
            "\n",
            "Epoch: 34\n",
            "\tTraining batch 1 Loss: 0.417042\n",
            "\tTraining batch 2 Loss: 0.537232\n",
            "\tTraining batch 3 Loss: 0.185671\n",
            "\tTraining batch 4 Loss: 0.513989\n",
            "\tTraining batch 5 Loss: 0.468739\n",
            "\tTraining batch 6 Loss: 0.499954\n",
            "\tTraining batch 7 Loss: 0.436393\n",
            "\tTraining batch 8 Loss: 0.390212\n",
            "\tTraining batch 9 Loss: 0.599935\n",
            "\tTraining batch 10 Loss: 0.321507\n",
            "\tTraining batch 11 Loss: 0.579683\n",
            "\tTraining batch 12 Loss: 0.281459\n",
            "\tTraining batch 13 Loss: 0.368096\n",
            "\tTraining batch 14 Loss: 0.346529\n",
            "\tTraining batch 15 Loss: 0.329423\n",
            "\tTraining batch 16 Loss: 0.382516\n",
            "\tTraining batch 17 Loss: 0.275523\n",
            "\tTraining batch 18 Loss: 0.677749\n",
            "Training set: Average loss: 0.422870\n",
            "Validation set: Average loss: 0.387427, Accuracy: 324/366 (89%)\n",
            "\n",
            "Epoch: 35\n",
            "\tTraining batch 1 Loss: 0.287472\n",
            "\tTraining batch 2 Loss: 0.252284\n",
            "\tTraining batch 3 Loss: 0.113504\n",
            "\tTraining batch 4 Loss: 0.485644\n",
            "\tTraining batch 5 Loss: 0.352834\n",
            "\tTraining batch 6 Loss: 0.339543\n",
            "\tTraining batch 7 Loss: 0.820279\n",
            "\tTraining batch 8 Loss: 0.289024\n",
            "\tTraining batch 9 Loss: 0.353712\n",
            "\tTraining batch 10 Loss: 0.295501\n",
            "\tTraining batch 11 Loss: 0.563224\n",
            "\tTraining batch 12 Loss: 0.258207\n",
            "\tTraining batch 13 Loss: 0.309422\n",
            "\tTraining batch 14 Loss: 0.422270\n",
            "\tTraining batch 15 Loss: 0.303168\n",
            "\tTraining batch 16 Loss: 0.390469\n",
            "\tTraining batch 17 Loss: 0.321560\n",
            "\tTraining batch 18 Loss: 0.359784\n",
            "Training set: Average loss: 0.362106\n",
            "Validation set: Average loss: 0.372425, Accuracy: 317/366 (87%)\n",
            "\n",
            "Epoch: 36\n",
            "\tTraining batch 1 Loss: 0.322540\n",
            "\tTraining batch 2 Loss: 0.396652\n",
            "\tTraining batch 3 Loss: 0.233410\n",
            "\tTraining batch 4 Loss: 0.607999\n",
            "\tTraining batch 5 Loss: 0.310877\n",
            "\tTraining batch 6 Loss: 0.334437\n",
            "\tTraining batch 7 Loss: 0.495096\n",
            "\tTraining batch 8 Loss: 0.323789\n",
            "\tTraining batch 9 Loss: 0.616787\n",
            "\tTraining batch 10 Loss: 0.259441\n",
            "\tTraining batch 11 Loss: 0.326326\n",
            "\tTraining batch 12 Loss: 0.371118\n",
            "\tTraining batch 13 Loss: 0.370025\n",
            "\tTraining batch 14 Loss: 0.443816\n",
            "\tTraining batch 15 Loss: 0.284492\n",
            "\tTraining batch 16 Loss: 0.248588\n",
            "\tTraining batch 17 Loss: 0.292095\n",
            "\tTraining batch 18 Loss: 0.851054\n",
            "Training set: Average loss: 0.393808\n",
            "Validation set: Average loss: 0.331542, Accuracy: 327/366 (89%)\n",
            "\n",
            "Epoch: 37\n",
            "\tTraining batch 1 Loss: 0.235019\n",
            "\tTraining batch 2 Loss: 0.383273\n",
            "\tTraining batch 3 Loss: 0.138906\n",
            "\tTraining batch 4 Loss: 0.346961\n",
            "\tTraining batch 5 Loss: 0.352018\n",
            "\tTraining batch 6 Loss: 0.336112\n",
            "\tTraining batch 7 Loss: 0.463588\n",
            "\tTraining batch 8 Loss: 0.322891\n",
            "\tTraining batch 9 Loss: 0.467363\n",
            "\tTraining batch 10 Loss: 0.472390\n",
            "\tTraining batch 11 Loss: 0.358327\n",
            "\tTraining batch 12 Loss: 0.260194\n",
            "\tTraining batch 13 Loss: 0.448174\n",
            "\tTraining batch 14 Loss: 0.418245\n",
            "\tTraining batch 15 Loss: 0.353711\n",
            "\tTraining batch 16 Loss: 0.360718\n",
            "\tTraining batch 17 Loss: 0.438425\n",
            "\tTraining batch 18 Loss: 0.633546\n",
            "Training set: Average loss: 0.377215\n",
            "Validation set: Average loss: 0.359429, Accuracy: 321/366 (88%)\n",
            "\n",
            "Epoch: 38\n",
            "\tTraining batch 1 Loss: 0.435723\n",
            "\tTraining batch 2 Loss: 0.237211\n",
            "\tTraining batch 3 Loss: 0.119484\n",
            "\tTraining batch 4 Loss: 0.553971\n",
            "\tTraining batch 5 Loss: 0.420406\n",
            "\tTraining batch 6 Loss: 0.335472\n",
            "\tTraining batch 7 Loss: 0.325062\n",
            "\tTraining batch 8 Loss: 0.327911\n",
            "\tTraining batch 9 Loss: 0.377756\n",
            "\tTraining batch 10 Loss: 0.307992\n",
            "\tTraining batch 11 Loss: 0.471586\n",
            "\tTraining batch 12 Loss: 0.188267\n",
            "\tTraining batch 13 Loss: 0.313704\n",
            "\tTraining batch 14 Loss: 0.338511\n",
            "\tTraining batch 15 Loss: 0.143504\n",
            "\tTraining batch 16 Loss: 0.401188\n",
            "\tTraining batch 17 Loss: 0.368813\n",
            "\tTraining batch 18 Loss: 0.443877\n",
            "Training set: Average loss: 0.339469\n",
            "Validation set: Average loss: 0.413756, Accuracy: 314/366 (86%)\n",
            "\n",
            "Epoch: 39\n",
            "\tTraining batch 1 Loss: 0.484115\n",
            "\tTraining batch 2 Loss: 0.332992\n",
            "\tTraining batch 3 Loss: 0.227387\n",
            "\tTraining batch 4 Loss: 0.310338\n",
            "\tTraining batch 5 Loss: 0.437470\n",
            "\tTraining batch 6 Loss: 0.343558\n",
            "\tTraining batch 7 Loss: 0.187135\n",
            "\tTraining batch 8 Loss: 0.360342\n",
            "\tTraining batch 9 Loss: 0.344672\n",
            "\tTraining batch 10 Loss: 0.308422\n",
            "\tTraining batch 11 Loss: 0.354043\n",
            "\tTraining batch 12 Loss: 0.157578\n",
            "\tTraining batch 13 Loss: 0.202320\n",
            "\tTraining batch 14 Loss: 0.188982\n",
            "\tTraining batch 15 Loss: 0.234073\n",
            "\tTraining batch 16 Loss: 0.334449\n",
            "\tTraining batch 17 Loss: 0.340629\n",
            "\tTraining batch 18 Loss: 0.080741\n",
            "Training set: Average loss: 0.290514\n",
            "Validation set: Average loss: 0.413303, Accuracy: 319/366 (87%)\n",
            "\n",
            "Epoch: 40\n",
            "\tTraining batch 1 Loss: 0.385008\n",
            "\tTraining batch 2 Loss: 0.381978\n",
            "\tTraining batch 3 Loss: 0.215276\n",
            "\tTraining batch 4 Loss: 0.222732\n",
            "\tTraining batch 5 Loss: 0.245687\n",
            "\tTraining batch 6 Loss: 0.407031\n",
            "\tTraining batch 7 Loss: 0.369613\n",
            "\tTraining batch 8 Loss: 0.344156\n",
            "\tTraining batch 9 Loss: 0.399462\n",
            "\tTraining batch 10 Loss: 0.289097\n",
            "\tTraining batch 11 Loss: 0.332249\n",
            "\tTraining batch 12 Loss: 0.380821\n",
            "\tTraining batch 13 Loss: 0.288748\n",
            "\tTraining batch 14 Loss: 0.204542\n",
            "\tTraining batch 15 Loss: 0.386016\n",
            "\tTraining batch 16 Loss: 0.303043\n",
            "\tTraining batch 17 Loss: 0.268379\n",
            "\tTraining batch 18 Loss: 0.224174\n",
            "Training set: Average loss: 0.313779\n",
            "Validation set: Average loss: 0.411061, Accuracy: 320/366 (87%)\n",
            "\n",
            "Epoch: 41\n",
            "\tTraining batch 1 Loss: 0.227613\n",
            "\tTraining batch 2 Loss: 0.255530\n",
            "\tTraining batch 3 Loss: 0.182705\n",
            "\tTraining batch 4 Loss: 0.607201\n",
            "\tTraining batch 5 Loss: 0.385314\n",
            "\tTraining batch 6 Loss: 0.300619\n",
            "\tTraining batch 7 Loss: 0.418888\n",
            "\tTraining batch 8 Loss: 0.364884\n",
            "\tTraining batch 9 Loss: 0.697561\n",
            "\tTraining batch 10 Loss: 0.348652\n",
            "\tTraining batch 11 Loss: 0.352326\n",
            "\tTraining batch 12 Loss: 0.248125\n",
            "\tTraining batch 13 Loss: 0.318858\n",
            "\tTraining batch 14 Loss: 0.436762\n",
            "\tTraining batch 15 Loss: 0.216909\n",
            "\tTraining batch 16 Loss: 0.324524\n",
            "\tTraining batch 17 Loss: 0.268641\n",
            "\tTraining batch 18 Loss: 0.215829\n",
            "Training set: Average loss: 0.342830\n",
            "Validation set: Average loss: 0.365528, Accuracy: 325/366 (89%)\n",
            "\n",
            "Epoch: 42\n",
            "\tTraining batch 1 Loss: 0.263596\n",
            "\tTraining batch 2 Loss: 0.460695\n",
            "\tTraining batch 3 Loss: 0.211714\n",
            "\tTraining batch 4 Loss: 0.332656\n",
            "\tTraining batch 5 Loss: 0.245734\n",
            "\tTraining batch 6 Loss: 0.393423\n",
            "\tTraining batch 7 Loss: 0.464054\n",
            "\tTraining batch 8 Loss: 0.216568\n",
            "\tTraining batch 9 Loss: 0.527776\n",
            "\tTraining batch 10 Loss: 0.334520\n",
            "\tTraining batch 11 Loss: 0.340236\n",
            "\tTraining batch 12 Loss: 0.232118\n",
            "\tTraining batch 13 Loss: 0.268954\n",
            "\tTraining batch 14 Loss: 0.207027\n",
            "\tTraining batch 15 Loss: 0.147003\n",
            "\tTraining batch 16 Loss: 0.318425\n",
            "\tTraining batch 17 Loss: 0.183158\n",
            "\tTraining batch 18 Loss: 0.526553\n",
            "Training set: Average loss: 0.315234\n",
            "Validation set: Average loss: 0.369255, Accuracy: 326/366 (89%)\n",
            "\n",
            "Epoch: 43\n",
            "\tTraining batch 1 Loss: 0.198901\n",
            "\tTraining batch 2 Loss: 0.182587\n",
            "\tTraining batch 3 Loss: 0.174294\n",
            "\tTraining batch 4 Loss: 0.333827\n",
            "\tTraining batch 5 Loss: 0.317923\n",
            "\tTraining batch 6 Loss: 0.228618\n",
            "\tTraining batch 7 Loss: 0.454881\n",
            "\tTraining batch 8 Loss: 0.230310\n",
            "\tTraining batch 9 Loss: 0.325283\n",
            "\tTraining batch 10 Loss: 0.276056\n",
            "\tTraining batch 11 Loss: 0.474100\n",
            "\tTraining batch 12 Loss: 0.291043\n",
            "\tTraining batch 13 Loss: 0.371266\n",
            "\tTraining batch 14 Loss: 0.472552\n",
            "\tTraining batch 15 Loss: 0.147876\n",
            "\tTraining batch 16 Loss: 0.341705\n",
            "\tTraining batch 17 Loss: 0.250573\n",
            "\tTraining batch 18 Loss: 0.671584\n",
            "Training set: Average loss: 0.319077\n",
            "Validation set: Average loss: 0.411001, Accuracy: 321/366 (88%)\n",
            "\n",
            "Epoch: 44\n",
            "\tTraining batch 1 Loss: 0.288447\n",
            "\tTraining batch 2 Loss: 0.451364\n",
            "\tTraining batch 3 Loss: 0.114366\n",
            "\tTraining batch 4 Loss: 0.300038\n",
            "\tTraining batch 5 Loss: 0.283192\n",
            "\tTraining batch 6 Loss: 0.307876\n",
            "\tTraining batch 7 Loss: 0.333982\n",
            "\tTraining batch 8 Loss: 0.192808\n",
            "\tTraining batch 9 Loss: 0.377492\n",
            "\tTraining batch 10 Loss: 0.297719\n",
            "\tTraining batch 11 Loss: 0.332359\n",
            "\tTraining batch 12 Loss: 0.182878\n",
            "\tTraining batch 13 Loss: 0.312626\n",
            "\tTraining batch 14 Loss: 0.128794\n",
            "\tTraining batch 15 Loss: 0.239451\n",
            "\tTraining batch 16 Loss: 0.262927\n",
            "\tTraining batch 17 Loss: 0.299833\n",
            "\tTraining batch 18 Loss: 0.574109\n",
            "Training set: Average loss: 0.293348\n",
            "Validation set: Average loss: 0.392187, Accuracy: 325/366 (89%)\n",
            "\n",
            "Epoch: 45\n",
            "\tTraining batch 1 Loss: 0.208050\n",
            "\tTraining batch 2 Loss: 0.350179\n",
            "\tTraining batch 3 Loss: 0.246392\n",
            "\tTraining batch 4 Loss: 0.364572\n",
            "\tTraining batch 5 Loss: 0.490172\n",
            "\tTraining batch 6 Loss: 0.329600\n",
            "\tTraining batch 7 Loss: 0.312049\n",
            "\tTraining batch 8 Loss: 0.282479\n",
            "\tTraining batch 9 Loss: 0.803856\n",
            "\tTraining batch 10 Loss: 0.186936\n",
            "\tTraining batch 11 Loss: 0.607632\n",
            "\tTraining batch 12 Loss: 0.286191\n",
            "\tTraining batch 13 Loss: 0.288977\n",
            "\tTraining batch 14 Loss: 0.203774\n",
            "\tTraining batch 15 Loss: 0.253645\n",
            "\tTraining batch 16 Loss: 0.159226\n",
            "\tTraining batch 17 Loss: 0.674959\n",
            "\tTraining batch 18 Loss: 0.289292\n",
            "Training set: Average loss: 0.352110\n",
            "Validation set: Average loss: 0.368042, Accuracy: 321/366 (88%)\n",
            "\n",
            "Epoch: 46\n",
            "\tTraining batch 1 Loss: 0.223709\n",
            "\tTraining batch 2 Loss: 0.342371\n",
            "\tTraining batch 3 Loss: 0.254208\n",
            "\tTraining batch 4 Loss: 0.421798\n",
            "\tTraining batch 5 Loss: 0.122291\n",
            "\tTraining batch 6 Loss: 0.301874\n",
            "\tTraining batch 7 Loss: 0.407672\n",
            "\tTraining batch 8 Loss: 0.497946\n",
            "\tTraining batch 9 Loss: 0.559400\n",
            "\tTraining batch 10 Loss: 0.312655\n",
            "\tTraining batch 11 Loss: 0.440867\n",
            "\tTraining batch 12 Loss: 0.197660\n",
            "\tTraining batch 13 Loss: 0.211099\n",
            "\tTraining batch 14 Loss: 0.316802\n",
            "\tTraining batch 15 Loss: 0.334528\n",
            "\tTraining batch 16 Loss: 0.360038\n",
            "\tTraining batch 17 Loss: 0.241322\n",
            "\tTraining batch 18 Loss: 0.096743\n",
            "Training set: Average loss: 0.313499\n",
            "Validation set: Average loss: 0.327083, Accuracy: 329/366 (90%)\n",
            "\n",
            "Epoch: 47\n",
            "\tTraining batch 1 Loss: 0.338723\n",
            "\tTraining batch 2 Loss: 0.425522\n",
            "\tTraining batch 3 Loss: 0.205121\n",
            "\tTraining batch 4 Loss: 0.349318\n",
            "\tTraining batch 5 Loss: 0.278628\n",
            "\tTraining batch 6 Loss: 0.419106\n",
            "\tTraining batch 7 Loss: 0.260906\n",
            "\tTraining batch 8 Loss: 0.203051\n",
            "\tTraining batch 9 Loss: 0.420718\n",
            "\tTraining batch 10 Loss: 0.301146\n",
            "\tTraining batch 11 Loss: 0.757812\n",
            "\tTraining batch 12 Loss: 0.194035\n",
            "\tTraining batch 13 Loss: 0.376541\n",
            "\tTraining batch 14 Loss: 0.149019\n",
            "\tTraining batch 15 Loss: 0.298544\n",
            "\tTraining batch 16 Loss: 0.335093\n",
            "\tTraining batch 17 Loss: 0.231579\n",
            "\tTraining batch 18 Loss: 0.411500\n",
            "Training set: Average loss: 0.330909\n",
            "Validation set: Average loss: 0.299515, Accuracy: 323/366 (88%)\n",
            "\n",
            "Epoch: 48\n",
            "\tTraining batch 1 Loss: 0.201904\n",
            "\tTraining batch 2 Loss: 0.316324\n",
            "\tTraining batch 3 Loss: 0.101494\n",
            "\tTraining batch 4 Loss: 0.283128\n",
            "\tTraining batch 5 Loss: 0.347076\n",
            "\tTraining batch 6 Loss: 0.231433\n",
            "\tTraining batch 7 Loss: 0.296238\n",
            "\tTraining batch 8 Loss: 0.378099\n",
            "\tTraining batch 9 Loss: 0.643936\n",
            "\tTraining batch 10 Loss: 0.525519\n",
            "\tTraining batch 11 Loss: 0.520000\n",
            "\tTraining batch 12 Loss: 0.167113\n",
            "\tTraining batch 13 Loss: 0.455910\n",
            "\tTraining batch 14 Loss: 0.623911\n",
            "\tTraining batch 15 Loss: 0.436022\n",
            "\tTraining batch 16 Loss: 0.318815\n",
            "\tTraining batch 17 Loss: 0.117922\n",
            "\tTraining batch 18 Loss: 0.004461\n",
            "Training set: Average loss: 0.331628\n",
            "Validation set: Average loss: 0.700936, Accuracy: 318/366 (87%)\n",
            "\n",
            "Epoch: 49\n",
            "\tTraining batch 1 Loss: 1.530572\n",
            "\tTraining batch 2 Loss: 0.647956\n",
            "\tTraining batch 3 Loss: 0.265742\n",
            "\tTraining batch 4 Loss: 0.320025\n",
            "\tTraining batch 5 Loss: 0.381213\n",
            "\tTraining batch 6 Loss: 0.379402\n",
            "\tTraining batch 7 Loss: 0.800200\n",
            "\tTraining batch 8 Loss: 0.220738\n",
            "\tTraining batch 9 Loss: 0.393257\n",
            "\tTraining batch 10 Loss: 0.480555\n",
            "\tTraining batch 11 Loss: 0.456076\n",
            "\tTraining batch 12 Loss: 0.464483\n",
            "\tTraining batch 13 Loss: 0.450114\n",
            "\tTraining batch 14 Loss: 0.203567\n",
            "\tTraining batch 15 Loss: 0.331224\n",
            "\tTraining batch 16 Loss: 0.383622\n",
            "\tTraining batch 17 Loss: 0.457951\n",
            "\tTraining batch 18 Loss: 0.072471\n",
            "Training set: Average loss: 0.457732\n",
            "Validation set: Average loss: 0.469496, Accuracy: 313/366 (86%)\n",
            "\n",
            "Epoch: 50\n",
            "\tTraining batch 1 Loss: 0.248387\n",
            "\tTraining batch 2 Loss: 0.286929\n",
            "\tTraining batch 3 Loss: 0.598368\n",
            "\tTraining batch 4 Loss: 0.560072\n",
            "\tTraining batch 5 Loss: 0.340426\n",
            "\tTraining batch 6 Loss: 0.369876\n",
            "\tTraining batch 7 Loss: 0.424704\n",
            "\tTraining batch 8 Loss: 0.382992\n",
            "\tTraining batch 9 Loss: 0.385056\n",
            "\tTraining batch 10 Loss: 0.213934\n",
            "\tTraining batch 11 Loss: 0.901413\n",
            "\tTraining batch 12 Loss: 0.392172\n",
            "\tTraining batch 13 Loss: 0.343313\n",
            "\tTraining batch 14 Loss: 0.468370\n",
            "\tTraining batch 15 Loss: 0.173617\n",
            "\tTraining batch 16 Loss: 0.275716\n",
            "\tTraining batch 17 Loss: 0.397386\n",
            "\tTraining batch 18 Loss: 0.705093\n",
            "Training set: Average loss: 0.414879\n",
            "Validation set: Average loss: 0.342932, Accuracy: 317/366 (87%)\n",
            "\n",
            "Epoch: 51\n",
            "\tTraining batch 1 Loss: 0.258836\n",
            "\tTraining batch 2 Loss: 0.330370\n",
            "\tTraining batch 3 Loss: 0.309125\n",
            "\tTraining batch 4 Loss: 0.534561\n",
            "\tTraining batch 5 Loss: 0.350520\n",
            "\tTraining batch 6 Loss: 0.379026\n",
            "\tTraining batch 7 Loss: 0.290266\n",
            "\tTraining batch 8 Loss: 0.414566\n",
            "\tTraining batch 9 Loss: 0.368076\n",
            "\tTraining batch 10 Loss: 0.339535\n",
            "\tTraining batch 11 Loss: 0.399801\n",
            "\tTraining batch 12 Loss: 0.339521\n",
            "\tTraining batch 13 Loss: 0.352108\n",
            "\tTraining batch 14 Loss: 0.297660\n",
            "\tTraining batch 15 Loss: 0.385610\n",
            "\tTraining batch 16 Loss: 0.455127\n",
            "\tTraining batch 17 Loss: 0.235916\n",
            "\tTraining batch 18 Loss: 0.666760\n",
            "Training set: Average loss: 0.372632\n",
            "Validation set: Average loss: 0.376654, Accuracy: 318/366 (87%)\n",
            "\n",
            "Epoch: 52\n",
            "\tTraining batch 1 Loss: 0.427611\n",
            "\tTraining batch 2 Loss: 0.349948\n",
            "\tTraining batch 3 Loss: 0.164377\n",
            "\tTraining batch 4 Loss: 0.300495\n",
            "\tTraining batch 5 Loss: 0.336076\n",
            "\tTraining batch 6 Loss: 0.378159\n",
            "\tTraining batch 7 Loss: 0.499373\n",
            "\tTraining batch 8 Loss: 0.159680\n",
            "\tTraining batch 9 Loss: 0.236007\n",
            "\tTraining batch 10 Loss: 0.223692\n",
            "\tTraining batch 11 Loss: 0.407059\n",
            "\tTraining batch 12 Loss: 0.267093\n",
            "\tTraining batch 13 Loss: 0.453678\n",
            "\tTraining batch 14 Loss: 0.280831\n",
            "\tTraining batch 15 Loss: 0.358071\n",
            "\tTraining batch 16 Loss: 0.200030\n",
            "\tTraining batch 17 Loss: 0.251181\n",
            "\tTraining batch 18 Loss: 0.046255\n",
            "Training set: Average loss: 0.296645\n",
            "Validation set: Average loss: 0.365592, Accuracy: 323/366 (88%)\n",
            "\n",
            "Epoch: 53\n",
            "\tTraining batch 1 Loss: 0.337001\n",
            "\tTraining batch 2 Loss: 0.195659\n",
            "\tTraining batch 3 Loss: 0.140648\n",
            "\tTraining batch 4 Loss: 0.270360\n",
            "\tTraining batch 5 Loss: 0.252477\n",
            "\tTraining batch 6 Loss: 0.444014\n",
            "\tTraining batch 7 Loss: 0.281810\n",
            "\tTraining batch 8 Loss: 0.202200\n",
            "\tTraining batch 9 Loss: 0.526878\n",
            "\tTraining batch 10 Loss: 0.136359\n",
            "\tTraining batch 11 Loss: 0.360091\n",
            "\tTraining batch 12 Loss: 0.255917\n",
            "\tTraining batch 13 Loss: 0.291469\n",
            "\tTraining batch 14 Loss: 0.204980\n",
            "\tTraining batch 15 Loss: 0.218789\n",
            "\tTraining batch 16 Loss: 0.201868\n",
            "\tTraining batch 17 Loss: 0.220729\n",
            "\tTraining batch 18 Loss: 0.015670\n",
            "Training set: Average loss: 0.253162\n",
            "Validation set: Average loss: 0.380104, Accuracy: 331/366 (90%)\n",
            "\n",
            "Epoch: 54\n",
            "\tTraining batch 1 Loss: 0.201245\n",
            "\tTraining batch 2 Loss: 0.229922\n",
            "\tTraining batch 3 Loss: 0.154582\n",
            "\tTraining batch 4 Loss: 0.329812\n",
            "\tTraining batch 5 Loss: 0.217965\n",
            "\tTraining batch 6 Loss: 0.252258\n",
            "\tTraining batch 7 Loss: 0.136295\n",
            "\tTraining batch 8 Loss: 0.280948\n",
            "\tTraining batch 9 Loss: 0.331203\n",
            "\tTraining batch 10 Loss: 0.159730\n",
            "\tTraining batch 11 Loss: 0.281392\n",
            "\tTraining batch 12 Loss: 0.234305\n",
            "\tTraining batch 13 Loss: 0.198872\n",
            "\tTraining batch 14 Loss: 0.176192\n",
            "\tTraining batch 15 Loss: 0.239326\n",
            "\tTraining batch 16 Loss: 0.248816\n",
            "\tTraining batch 17 Loss: 0.272570\n",
            "\tTraining batch 18 Loss: 0.001458\n",
            "Training set: Average loss: 0.219272\n",
            "Validation set: Average loss: 0.355667, Accuracy: 328/366 (90%)\n",
            "\n",
            "Epoch: 55\n",
            "\tTraining batch 1 Loss: 0.175484\n",
            "\tTraining batch 2 Loss: 0.146989\n",
            "\tTraining batch 3 Loss: 0.061968\n",
            "\tTraining batch 4 Loss: 0.196293\n",
            "\tTraining batch 5 Loss: 0.279201\n",
            "\tTraining batch 6 Loss: 0.182832\n",
            "\tTraining batch 7 Loss: 0.212807\n",
            "\tTraining batch 8 Loss: 0.239349\n",
            "\tTraining batch 9 Loss: 0.288148\n",
            "\tTraining batch 10 Loss: 0.129127\n",
            "\tTraining batch 11 Loss: 0.220366\n",
            "\tTraining batch 12 Loss: 0.135367\n",
            "\tTraining batch 13 Loss: 0.317773\n",
            "\tTraining batch 14 Loss: 0.178693\n",
            "\tTraining batch 15 Loss: 0.139122\n",
            "\tTraining batch 16 Loss: 0.336805\n",
            "\tTraining batch 17 Loss: 0.359484\n",
            "\tTraining batch 18 Loss: 0.093243\n",
            "Training set: Average loss: 0.205170\n",
            "Validation set: Average loss: 0.416941, Accuracy: 330/366 (90%)\n",
            "\n",
            "Epoch: 56\n",
            "\tTraining batch 1 Loss: 0.316406\n",
            "\tTraining batch 2 Loss: 0.140617\n",
            "\tTraining batch 3 Loss: 0.170958\n",
            "\tTraining batch 4 Loss: 0.229383\n",
            "\tTraining batch 5 Loss: 0.338497\n",
            "\tTraining batch 6 Loss: 0.174081\n",
            "\tTraining batch 7 Loss: 0.338488\n",
            "\tTraining batch 8 Loss: 0.260850\n",
            "\tTraining batch 9 Loss: 0.331900\n",
            "\tTraining batch 10 Loss: 0.205499\n",
            "\tTraining batch 11 Loss: 0.325150\n",
            "\tTraining batch 12 Loss: 0.181620\n",
            "\tTraining batch 13 Loss: 0.149625\n",
            "\tTraining batch 14 Loss: 0.314117\n",
            "\tTraining batch 15 Loss: 0.149648\n",
            "\tTraining batch 16 Loss: 0.466745\n",
            "\tTraining batch 17 Loss: 0.316650\n",
            "\tTraining batch 18 Loss: 0.006421\n",
            "Training set: Average loss: 0.245370\n",
            "Validation set: Average loss: 0.321014, Accuracy: 334/366 (91%)\n",
            "\n",
            "Epoch: 57\n",
            "\tTraining batch 1 Loss: 0.245664\n",
            "\tTraining batch 2 Loss: 0.163943\n",
            "\tTraining batch 3 Loss: 0.078567\n",
            "\tTraining batch 4 Loss: 0.417966\n",
            "\tTraining batch 5 Loss: 0.319485\n",
            "\tTraining batch 6 Loss: 0.283978\n",
            "\tTraining batch 7 Loss: 0.245057\n",
            "\tTraining batch 8 Loss: 0.160149\n",
            "\tTraining batch 9 Loss: 0.211684\n",
            "\tTraining batch 10 Loss: 0.178636\n",
            "\tTraining batch 11 Loss: 0.415172\n",
            "\tTraining batch 12 Loss: 0.080388\n",
            "\tTraining batch 13 Loss: 0.324480\n",
            "\tTraining batch 14 Loss: 0.254834\n",
            "\tTraining batch 15 Loss: 0.144752\n",
            "\tTraining batch 16 Loss: 0.215265\n",
            "\tTraining batch 17 Loss: 0.092535\n",
            "\tTraining batch 18 Loss: 0.040153\n",
            "Training set: Average loss: 0.215150\n",
            "Validation set: Average loss: 0.327566, Accuracy: 332/366 (91%)\n",
            "\n",
            "Epoch: 58\n",
            "\tTraining batch 1 Loss: 0.462623\n",
            "\tTraining batch 2 Loss: 0.274249\n",
            "\tTraining batch 3 Loss: 0.106196\n",
            "\tTraining batch 4 Loss: 0.264343\n",
            "\tTraining batch 5 Loss: 0.257533\n",
            "\tTraining batch 6 Loss: 0.221284\n",
            "\tTraining batch 7 Loss: 0.177383\n",
            "\tTraining batch 8 Loss: 0.412880\n",
            "\tTraining batch 9 Loss: 0.334565\n",
            "\tTraining batch 10 Loss: 0.350740\n",
            "\tTraining batch 11 Loss: 0.278989\n",
            "\tTraining batch 12 Loss: 0.125498\n",
            "\tTraining batch 13 Loss: 0.169735\n",
            "\tTraining batch 14 Loss: 0.084232\n",
            "\tTraining batch 15 Loss: 0.191136\n",
            "\tTraining batch 16 Loss: 0.234213\n",
            "\tTraining batch 17 Loss: 0.300161\n",
            "\tTraining batch 18 Loss: 0.086244\n",
            "Training set: Average loss: 0.240667\n",
            "Validation set: Average loss: 0.407291, Accuracy: 329/366 (90%)\n",
            "\n",
            "Epoch: 59\n",
            "\tTraining batch 1 Loss: 0.207664\n",
            "\tTraining batch 2 Loss: 0.155738\n",
            "\tTraining batch 3 Loss: 0.151776\n",
            "\tTraining batch 4 Loss: 0.150703\n",
            "\tTraining batch 5 Loss: 0.169248\n",
            "\tTraining batch 6 Loss: 0.204388\n",
            "\tTraining batch 7 Loss: 0.206359\n",
            "\tTraining batch 8 Loss: 0.147688\n",
            "\tTraining batch 9 Loss: 0.319866\n",
            "\tTraining batch 10 Loss: 0.240262\n",
            "\tTraining batch 11 Loss: 0.267628\n",
            "\tTraining batch 12 Loss: 0.241245\n",
            "\tTraining batch 13 Loss: 0.217549\n",
            "\tTraining batch 14 Loss: 0.224158\n",
            "\tTraining batch 15 Loss: 0.271142\n",
            "\tTraining batch 16 Loss: 0.384162\n",
            "\tTraining batch 17 Loss: 0.252924\n",
            "\tTraining batch 18 Loss: 0.120257\n",
            "Training set: Average loss: 0.218487\n",
            "Validation set: Average loss: 0.342943, Accuracy: 328/366 (90%)\n",
            "\n",
            "Epoch: 60\n",
            "\tTraining batch 1 Loss: 0.122832\n",
            "\tTraining batch 2 Loss: 0.281936\n",
            "\tTraining batch 3 Loss: 0.191049\n",
            "\tTraining batch 4 Loss: 0.228993\n",
            "\tTraining batch 5 Loss: 0.294748\n",
            "\tTraining batch 6 Loss: 0.154997\n",
            "\tTraining batch 7 Loss: 0.120038\n",
            "\tTraining batch 8 Loss: 0.307419\n",
            "\tTraining batch 9 Loss: 0.517295\n",
            "\tTraining batch 10 Loss: 0.255235\n",
            "\tTraining batch 11 Loss: 0.387823\n",
            "\tTraining batch 12 Loss: 0.215448\n",
            "\tTraining batch 13 Loss: 0.240111\n",
            "\tTraining batch 14 Loss: 0.292916\n",
            "\tTraining batch 15 Loss: 0.219089\n",
            "\tTraining batch 16 Loss: 0.255860\n",
            "\tTraining batch 17 Loss: 0.323642\n",
            "\tTraining batch 18 Loss: 0.005513\n",
            "Training set: Average loss: 0.245275\n",
            "Validation set: Average loss: 0.349002, Accuracy: 327/366 (89%)\n",
            "\n",
            "Epoch: 61\n",
            "\tTraining batch 1 Loss: 0.302271\n",
            "\tTraining batch 2 Loss: 0.221674\n",
            "\tTraining batch 3 Loss: 0.132799\n",
            "\tTraining batch 4 Loss: 0.236550\n",
            "\tTraining batch 5 Loss: 0.404483\n",
            "\tTraining batch 6 Loss: 0.261419\n",
            "\tTraining batch 7 Loss: 0.198534\n",
            "\tTraining batch 8 Loss: 0.379348\n",
            "\tTraining batch 9 Loss: 0.296312\n",
            "\tTraining batch 10 Loss: 0.192935\n",
            "\tTraining batch 11 Loss: 0.316186\n",
            "\tTraining batch 12 Loss: 0.278222\n",
            "\tTraining batch 13 Loss: 0.253867\n",
            "\tTraining batch 14 Loss: 0.228580\n",
            "\tTraining batch 15 Loss: 0.220716\n",
            "\tTraining batch 16 Loss: 0.382778\n",
            "\tTraining batch 17 Loss: 0.273846\n",
            "\tTraining batch 18 Loss: 0.011226\n",
            "Training set: Average loss: 0.255097\n",
            "Validation set: Average loss: 0.338133, Accuracy: 328/366 (90%)\n",
            "\n",
            "Epoch: 62\n",
            "\tTraining batch 1 Loss: 0.173946\n",
            "\tTraining batch 2 Loss: 0.165297\n",
            "\tTraining batch 3 Loss: 0.124482\n",
            "\tTraining batch 4 Loss: 0.402880\n",
            "\tTraining batch 5 Loss: 0.329834\n",
            "\tTraining batch 6 Loss: 0.264556\n",
            "\tTraining batch 7 Loss: 0.319193\n",
            "\tTraining batch 8 Loss: 0.167544\n",
            "\tTraining batch 9 Loss: 0.222841\n",
            "\tTraining batch 10 Loss: 0.322348\n",
            "\tTraining batch 11 Loss: 0.307644\n",
            "\tTraining batch 12 Loss: 0.242372\n",
            "\tTraining batch 13 Loss: 0.345839\n",
            "\tTraining batch 14 Loss: 0.237686\n",
            "\tTraining batch 15 Loss: 0.185606\n",
            "\tTraining batch 16 Loss: 0.393346\n",
            "\tTraining batch 17 Loss: 0.170623\n",
            "\tTraining batch 18 Loss: 0.170180\n",
            "Training set: Average loss: 0.252568\n",
            "Validation set: Average loss: 0.351081, Accuracy: 328/366 (90%)\n",
            "\n",
            "Epoch: 63\n",
            "\tTraining batch 1 Loss: 0.374743\n",
            "\tTraining batch 2 Loss: 0.360383\n",
            "\tTraining batch 3 Loss: 0.220035\n",
            "\tTraining batch 4 Loss: 0.364655\n",
            "\tTraining batch 5 Loss: 0.342409\n",
            "\tTraining batch 6 Loss: 0.274001\n",
            "\tTraining batch 7 Loss: 0.219937\n",
            "\tTraining batch 8 Loss: 0.404012\n",
            "\tTraining batch 9 Loss: 0.246987\n",
            "\tTraining batch 10 Loss: 0.195752\n",
            "\tTraining batch 11 Loss: 0.426236\n",
            "\tTraining batch 12 Loss: 0.198012\n",
            "\tTraining batch 13 Loss: 0.571372\n",
            "\tTraining batch 14 Loss: 0.286308\n",
            "\tTraining batch 15 Loss: 0.082835\n",
            "\tTraining batch 16 Loss: 0.219653\n",
            "\tTraining batch 17 Loss: 0.105319\n",
            "\tTraining batch 18 Loss: 0.058639\n",
            "Training set: Average loss: 0.275072\n",
            "Validation set: Average loss: 0.337895, Accuracy: 322/366 (88%)\n",
            "\n",
            "Epoch: 64\n",
            "\tTraining batch 1 Loss: 0.260101\n",
            "\tTraining batch 2 Loss: 0.431435\n",
            "\tTraining batch 3 Loss: 0.083228\n",
            "\tTraining batch 4 Loss: 0.291279\n",
            "\tTraining batch 5 Loss: 0.172966\n",
            "\tTraining batch 6 Loss: 0.246754\n",
            "\tTraining batch 7 Loss: 0.145766\n",
            "\tTraining batch 8 Loss: 0.166007\n",
            "\tTraining batch 9 Loss: 0.459850\n",
            "\tTraining batch 10 Loss: 0.226133\n",
            "\tTraining batch 11 Loss: 0.357486\n",
            "\tTraining batch 12 Loss: 0.215899\n",
            "\tTraining batch 13 Loss: 0.377769\n",
            "\tTraining batch 14 Loss: 0.230895\n",
            "\tTraining batch 15 Loss: 0.108544\n",
            "\tTraining batch 16 Loss: 0.266217\n",
            "\tTraining batch 17 Loss: 0.278602\n",
            "\tTraining batch 18 Loss: 0.556374\n",
            "Training set: Average loss: 0.270850\n",
            "Validation set: Average loss: 0.397653, Accuracy: 330/366 (90%)\n",
            "\n",
            "Epoch: 65\n",
            "\tTraining batch 1 Loss: 0.267594\n",
            "\tTraining batch 2 Loss: 0.135001\n",
            "\tTraining batch 3 Loss: 0.095305\n",
            "\tTraining batch 4 Loss: 0.252430\n",
            "\tTraining batch 5 Loss: 0.206645\n",
            "\tTraining batch 6 Loss: 0.271925\n",
            "\tTraining batch 7 Loss: 0.120840\n",
            "\tTraining batch 8 Loss: 0.600956\n",
            "\tTraining batch 9 Loss: 0.149274\n",
            "\tTraining batch 10 Loss: 0.194463\n",
            "\tTraining batch 11 Loss: 0.304277\n",
            "\tTraining batch 12 Loss: 0.191266\n",
            "\tTraining batch 13 Loss: 0.291719\n",
            "\tTraining batch 14 Loss: 0.140898\n",
            "\tTraining batch 15 Loss: 0.211609\n",
            "\tTraining batch 16 Loss: 0.418631\n",
            "\tTraining batch 17 Loss: 0.258951\n",
            "\tTraining batch 18 Loss: 0.477312\n",
            "Training set: Average loss: 0.254950\n",
            "Validation set: Average loss: 0.346371, Accuracy: 319/366 (87%)\n",
            "\n",
            "Epoch: 66\n",
            "\tTraining batch 1 Loss: 0.230831\n",
            "\tTraining batch 2 Loss: 0.203003\n",
            "\tTraining batch 3 Loss: 0.121091\n",
            "\tTraining batch 4 Loss: 0.408707\n",
            "\tTraining batch 5 Loss: 0.507969\n",
            "\tTraining batch 6 Loss: 0.208365\n",
            "\tTraining batch 7 Loss: 0.352218\n",
            "\tTraining batch 8 Loss: 0.235713\n",
            "\tTraining batch 9 Loss: 0.286455\n",
            "\tTraining batch 10 Loss: 0.163468\n",
            "\tTraining batch 11 Loss: 0.342773\n",
            "\tTraining batch 12 Loss: 0.151373\n",
            "\tTraining batch 13 Loss: 0.486206\n",
            "\tTraining batch 14 Loss: 0.283728\n",
            "\tTraining batch 15 Loss: 0.282871\n",
            "\tTraining batch 16 Loss: 0.249755\n",
            "\tTraining batch 17 Loss: 0.213032\n",
            "\tTraining batch 18 Loss: 0.016019\n",
            "Training set: Average loss: 0.263532\n",
            "Validation set: Average loss: 0.427360, Accuracy: 332/366 (91%)\n",
            "\n",
            "Epoch: 67\n",
            "\tTraining batch 1 Loss: 0.200148\n",
            "\tTraining batch 2 Loss: 0.311121\n",
            "\tTraining batch 3 Loss: 0.211121\n",
            "\tTraining batch 4 Loss: 0.252521\n",
            "\tTraining batch 5 Loss: 0.178779\n",
            "\tTraining batch 6 Loss: 0.292354\n",
            "\tTraining batch 7 Loss: 0.274076\n",
            "\tTraining batch 8 Loss: 0.170962\n",
            "\tTraining batch 9 Loss: 0.324136\n",
            "\tTraining batch 10 Loss: 0.178566\n",
            "\tTraining batch 11 Loss: 0.470242\n",
            "\tTraining batch 12 Loss: 0.152120\n",
            "\tTraining batch 13 Loss: 0.310635\n",
            "\tTraining batch 14 Loss: 0.197279\n",
            "\tTraining batch 15 Loss: 0.095342\n",
            "\tTraining batch 16 Loss: 0.179278\n",
            "\tTraining batch 17 Loss: 0.183730\n",
            "\tTraining batch 18 Loss: 0.000033\n",
            "Training set: Average loss: 0.221247\n",
            "Validation set: Average loss: 0.357747, Accuracy: 323/366 (88%)\n",
            "\n",
            "Epoch: 68\n",
            "\tTraining batch 1 Loss: 0.584042\n",
            "\tTraining batch 2 Loss: 0.201187\n",
            "\tTraining batch 3 Loss: 0.103000\n",
            "\tTraining batch 4 Loss: 0.241097\n",
            "\tTraining batch 5 Loss: 0.383393\n",
            "\tTraining batch 6 Loss: 0.280535\n",
            "\tTraining batch 7 Loss: 0.234870\n",
            "\tTraining batch 8 Loss: 0.127733\n",
            "\tTraining batch 9 Loss: 0.313944\n",
            "\tTraining batch 10 Loss: 0.234551\n",
            "\tTraining batch 11 Loss: 0.480874\n",
            "\tTraining batch 12 Loss: 0.117656\n",
            "\tTraining batch 13 Loss: 0.240121\n",
            "\tTraining batch 14 Loss: 0.248345\n",
            "\tTraining batch 15 Loss: 0.133685\n",
            "\tTraining batch 16 Loss: 0.311493\n",
            "\tTraining batch 17 Loss: 0.151608\n",
            "\tTraining batch 18 Loss: 0.013647\n",
            "Training set: Average loss: 0.244543\n",
            "Validation set: Average loss: 0.379040, Accuracy: 330/366 (90%)\n",
            "\n",
            "Epoch: 69\n",
            "\tTraining batch 1 Loss: 0.205888\n",
            "\tTraining batch 2 Loss: 0.152724\n",
            "\tTraining batch 3 Loss: 0.104697\n",
            "\tTraining batch 4 Loss: 0.129557\n",
            "\tTraining batch 5 Loss: 0.339094\n",
            "\tTraining batch 6 Loss: 0.133711\n",
            "\tTraining batch 7 Loss: 0.164246\n",
            "\tTraining batch 8 Loss: 0.204244\n",
            "\tTraining batch 9 Loss: 0.181078\n",
            "\tTraining batch 10 Loss: 0.217234\n",
            "\tTraining batch 11 Loss: 0.270236\n",
            "\tTraining batch 12 Loss: 0.290810\n",
            "\tTraining batch 13 Loss: 0.167249\n",
            "\tTraining batch 14 Loss: 0.177617\n",
            "\tTraining batch 15 Loss: 0.230763\n",
            "\tTraining batch 16 Loss: 0.245472\n",
            "\tTraining batch 17 Loss: 0.208126\n",
            "\tTraining batch 18 Loss: 0.011864\n",
            "Training set: Average loss: 0.190812\n",
            "Validation set: Average loss: 0.278096, Accuracy: 335/366 (92%)\n",
            "\n",
            "Epoch: 70\n",
            "\tTraining batch 1 Loss: 0.251894\n",
            "\tTraining batch 2 Loss: 0.216238\n",
            "\tTraining batch 3 Loss: 0.057074\n",
            "\tTraining batch 4 Loss: 0.196748\n",
            "\tTraining batch 5 Loss: 0.193032\n",
            "\tTraining batch 6 Loss: 0.287307\n",
            "\tTraining batch 7 Loss: 0.224298\n",
            "\tTraining batch 8 Loss: 0.283733\n",
            "\tTraining batch 9 Loss: 0.365524\n",
            "\tTraining batch 10 Loss: 0.164818\n",
            "\tTraining batch 11 Loss: 0.328238\n",
            "\tTraining batch 12 Loss: 0.193660\n",
            "\tTraining batch 13 Loss: 0.190028\n",
            "\tTraining batch 14 Loss: 0.160373\n",
            "\tTraining batch 15 Loss: 0.336674\n",
            "\tTraining batch 16 Loss: 0.166350\n",
            "\tTraining batch 17 Loss: 0.122910\n",
            "\tTraining batch 18 Loss: 1.698220\n",
            "Training set: Average loss: 0.302062\n",
            "Validation set: Average loss: 0.323230, Accuracy: 331/366 (90%)\n",
            "\n",
            "Epoch: 71\n",
            "\tTraining batch 1 Loss: 0.266340\n",
            "\tTraining batch 2 Loss: 0.325153\n",
            "\tTraining batch 3 Loss: 0.359118\n",
            "\tTraining batch 4 Loss: 1.474795\n",
            "\tTraining batch 5 Loss: 0.370620\n",
            "\tTraining batch 6 Loss: 0.431291\n",
            "\tTraining batch 7 Loss: 0.444061\n",
            "\tTraining batch 8 Loss: 0.643090\n",
            "\tTraining batch 9 Loss: 0.584321\n",
            "\tTraining batch 10 Loss: 0.421118\n",
            "\tTraining batch 11 Loss: 0.631606\n",
            "\tTraining batch 12 Loss: 0.632880\n",
            "\tTraining batch 13 Loss: 0.629663\n",
            "\tTraining batch 14 Loss: 0.366907\n",
            "\tTraining batch 15 Loss: 0.317622\n",
            "\tTraining batch 16 Loss: 0.836668\n",
            "\tTraining batch 17 Loss: 0.570974\n",
            "\tTraining batch 18 Loss: 0.470002\n",
            "Training set: Average loss: 0.543124\n",
            "Validation set: Average loss: 0.417356, Accuracy: 307/366 (84%)\n",
            "\n",
            "Epoch: 72\n",
            "\tTraining batch 1 Loss: 0.482373\n",
            "\tTraining batch 2 Loss: 0.349087\n",
            "\tTraining batch 3 Loss: 0.258839\n",
            "\tTraining batch 4 Loss: 0.266107\n",
            "\tTraining batch 5 Loss: 0.550295\n",
            "\tTraining batch 6 Loss: 0.426099\n",
            "\tTraining batch 7 Loss: 0.282704\n",
            "\tTraining batch 8 Loss: 0.212701\n",
            "\tTraining batch 9 Loss: 0.389633\n",
            "\tTraining batch 10 Loss: 0.332616\n",
            "\tTraining batch 11 Loss: 0.632910\n",
            "\tTraining batch 12 Loss: 0.310930\n",
            "\tTraining batch 13 Loss: 0.334252\n",
            "\tTraining batch 14 Loss: 0.632883\n",
            "\tTraining batch 15 Loss: 0.359978\n",
            "\tTraining batch 16 Loss: 0.417346\n",
            "\tTraining batch 17 Loss: 0.237337\n",
            "\tTraining batch 18 Loss: 0.443607\n",
            "Training set: Average loss: 0.384428\n",
            "Validation set: Average loss: 0.491617, Accuracy: 313/366 (86%)\n",
            "\n",
            "Epoch: 73\n",
            "\tTraining batch 1 Loss: 0.447244\n",
            "\tTraining batch 2 Loss: 0.267124\n",
            "\tTraining batch 3 Loss: 0.284445\n",
            "\tTraining batch 4 Loss: 0.348709\n",
            "\tTraining batch 5 Loss: 0.397155\n",
            "\tTraining batch 6 Loss: 0.332008\n",
            "\tTraining batch 7 Loss: 0.499228\n",
            "\tTraining batch 8 Loss: 0.568825\n",
            "\tTraining batch 9 Loss: 0.448202\n",
            "\tTraining batch 10 Loss: 0.265889\n",
            "\tTraining batch 11 Loss: 0.604998\n",
            "\tTraining batch 12 Loss: 0.341555\n",
            "\tTraining batch 13 Loss: 0.303424\n",
            "\tTraining batch 14 Loss: 0.241988\n",
            "\tTraining batch 15 Loss: 0.341390\n",
            "\tTraining batch 16 Loss: 0.369478\n",
            "\tTraining batch 17 Loss: 0.256801\n",
            "\tTraining batch 18 Loss: 0.346691\n",
            "Training set: Average loss: 0.370286\n",
            "Validation set: Average loss: 0.420104, Accuracy: 320/366 (87%)\n",
            "\n",
            "Epoch: 74\n",
            "\tTraining batch 1 Loss: 0.338316\n",
            "\tTraining batch 2 Loss: 0.519139\n",
            "\tTraining batch 3 Loss: 0.179204\n",
            "\tTraining batch 4 Loss: 0.438821\n",
            "\tTraining batch 5 Loss: 0.345174\n",
            "\tTraining batch 6 Loss: 0.488707\n",
            "\tTraining batch 7 Loss: 0.128497\n",
            "\tTraining batch 8 Loss: 0.190285\n",
            "\tTraining batch 9 Loss: 0.224584\n",
            "\tTraining batch 10 Loss: 0.155816\n",
            "\tTraining batch 11 Loss: 0.326053\n",
            "\tTraining batch 12 Loss: 0.232914\n",
            "\tTraining batch 13 Loss: 0.258370\n",
            "\tTraining batch 14 Loss: 0.124453\n",
            "\tTraining batch 15 Loss: 0.271517\n",
            "\tTraining batch 16 Loss: 0.408647\n",
            "\tTraining batch 17 Loss: 0.446707\n",
            "\tTraining batch 18 Loss: 0.134694\n",
            "Training set: Average loss: 0.289550\n",
            "Validation set: Average loss: 0.443183, Accuracy: 332/366 (91%)\n",
            "\n",
            "Epoch: 75\n",
            "\tTraining batch 1 Loss: 0.595544\n",
            "\tTraining batch 2 Loss: 0.177310\n",
            "\tTraining batch 3 Loss: 0.114774\n",
            "\tTraining batch 4 Loss: 0.344728\n",
            "\tTraining batch 5 Loss: 0.294242\n",
            "\tTraining batch 6 Loss: 0.328309\n",
            "\tTraining batch 7 Loss: 0.104721\n",
            "\tTraining batch 8 Loss: 0.317556\n",
            "\tTraining batch 9 Loss: 0.517351\n",
            "\tTraining batch 10 Loss: 0.312830\n",
            "\tTraining batch 11 Loss: 0.586609\n",
            "\tTraining batch 12 Loss: 0.176318\n",
            "\tTraining batch 13 Loss: 0.176434\n",
            "\tTraining batch 14 Loss: 0.206778\n",
            "\tTraining batch 15 Loss: 0.277172\n",
            "\tTraining batch 16 Loss: 0.503890\n",
            "\tTraining batch 17 Loss: 0.274389\n",
            "\tTraining batch 18 Loss: 0.026289\n",
            "Training set: Average loss: 0.296402\n",
            "Validation set: Average loss: 0.364759, Accuracy: 322/366 (88%)\n",
            "\n",
            "Epoch: 76\n",
            "\tTraining batch 1 Loss: 0.280078\n",
            "\tTraining batch 2 Loss: 0.233927\n",
            "\tTraining batch 3 Loss: 0.165284\n",
            "\tTraining batch 4 Loss: 0.261767\n",
            "\tTraining batch 5 Loss: 0.359981\n",
            "\tTraining batch 6 Loss: 0.246508\n",
            "\tTraining batch 7 Loss: 0.161134\n",
            "\tTraining batch 8 Loss: 0.436296\n",
            "\tTraining batch 9 Loss: 0.371546\n",
            "\tTraining batch 10 Loss: 0.364711\n",
            "\tTraining batch 11 Loss: 0.281482\n",
            "\tTraining batch 12 Loss: 0.381018\n",
            "\tTraining batch 13 Loss: 0.202523\n",
            "\tTraining batch 14 Loss: 0.197186\n",
            "\tTraining batch 15 Loss: 0.238389\n",
            "\tTraining batch 16 Loss: 0.427994\n",
            "\tTraining batch 17 Loss: 0.109150\n",
            "\tTraining batch 18 Loss: 0.332971\n",
            "Training set: Average loss: 0.280664\n",
            "Validation set: Average loss: 0.368075, Accuracy: 329/366 (90%)\n",
            "\n",
            "Epoch: 77\n",
            "\tTraining batch 1 Loss: 0.219984\n",
            "\tTraining batch 2 Loss: 0.137562\n",
            "\tTraining batch 3 Loss: 0.092693\n",
            "\tTraining batch 4 Loss: 0.220286\n",
            "\tTraining batch 5 Loss: 0.289125\n",
            "\tTraining batch 6 Loss: 0.221942\n",
            "\tTraining batch 7 Loss: 0.228545\n",
            "\tTraining batch 8 Loss: 0.267324\n",
            "\tTraining batch 9 Loss: 0.358559\n",
            "\tTraining batch 10 Loss: 0.205365\n",
            "\tTraining batch 11 Loss: 0.395127\n",
            "\tTraining batch 12 Loss: 0.161435\n",
            "\tTraining batch 13 Loss: 0.263657\n",
            "\tTraining batch 14 Loss: 0.163197\n",
            "\tTraining batch 15 Loss: 0.178763\n",
            "\tTraining batch 16 Loss: 0.343188\n",
            "\tTraining batch 17 Loss: 0.194801\n",
            "\tTraining batch 18 Loss: 0.002624\n",
            "Training set: Average loss: 0.219121\n",
            "Validation set: Average loss: 0.428346, Accuracy: 324/366 (89%)\n",
            "\n",
            "Epoch: 78\n",
            "\tTraining batch 1 Loss: 0.299762\n",
            "\tTraining batch 2 Loss: 0.162795\n",
            "\tTraining batch 3 Loss: 0.140216\n",
            "\tTraining batch 4 Loss: 0.245082\n",
            "\tTraining batch 5 Loss: 0.253536\n",
            "\tTraining batch 6 Loss: 0.472491\n",
            "\tTraining batch 7 Loss: 0.296695\n",
            "\tTraining batch 8 Loss: 0.253861\n",
            "\tTraining batch 9 Loss: 0.352266\n",
            "\tTraining batch 10 Loss: 0.123232\n",
            "\tTraining batch 11 Loss: 0.249694\n",
            "\tTraining batch 12 Loss: 0.107066\n",
            "\tTraining batch 13 Loss: 0.397559\n",
            "\tTraining batch 14 Loss: 0.352556\n",
            "\tTraining batch 15 Loss: 0.191122\n",
            "\tTraining batch 16 Loss: 0.270125\n",
            "\tTraining batch 17 Loss: 0.231610\n",
            "\tTraining batch 18 Loss: 0.124300\n",
            "Training set: Average loss: 0.251332\n",
            "Validation set: Average loss: 0.315052, Accuracy: 338/366 (92%)\n",
            "\n",
            "Epoch: 79\n",
            "\tTraining batch 1 Loss: 0.465117\n",
            "\tTraining batch 2 Loss: 0.245226\n",
            "\tTraining batch 3 Loss: 0.197336\n",
            "\tTraining batch 4 Loss: 0.332346\n",
            "\tTraining batch 5 Loss: 0.243829\n",
            "\tTraining batch 6 Loss: 0.184467\n",
            "\tTraining batch 7 Loss: 0.389928\n",
            "\tTraining batch 8 Loss: 0.289430\n",
            "\tTraining batch 9 Loss: 0.192101\n",
            "\tTraining batch 10 Loss: 0.175321\n",
            "\tTraining batch 11 Loss: 0.197631\n",
            "\tTraining batch 12 Loss: 0.140116\n",
            "\tTraining batch 13 Loss: 0.309036\n",
            "\tTraining batch 14 Loss: 0.079708\n",
            "\tTraining batch 15 Loss: 0.117003\n",
            "\tTraining batch 16 Loss: 0.446754\n",
            "\tTraining batch 17 Loss: 0.125212\n",
            "\tTraining batch 18 Loss: 0.002264\n",
            "Training set: Average loss: 0.229601\n",
            "Validation set: Average loss: 0.383326, Accuracy: 326/366 (89%)\n",
            "\n",
            "Epoch: 80\n",
            "\tTraining batch 1 Loss: 0.330743\n",
            "\tTraining batch 2 Loss: 0.192732\n",
            "\tTraining batch 3 Loss: 0.115482\n",
            "\tTraining batch 4 Loss: 0.421289\n",
            "\tTraining batch 5 Loss: 0.288047\n",
            "\tTraining batch 6 Loss: 0.181365\n",
            "\tTraining batch 7 Loss: 0.195015\n",
            "\tTraining batch 8 Loss: 0.490901\n",
            "\tTraining batch 9 Loss: 0.419713\n",
            "\tTraining batch 10 Loss: 0.170585\n",
            "\tTraining batch 11 Loss: 0.273229\n",
            "\tTraining batch 12 Loss: 0.114724\n",
            "\tTraining batch 13 Loss: 0.433066\n",
            "\tTraining batch 14 Loss: 0.281427\n",
            "\tTraining batch 15 Loss: 0.097050\n",
            "\tTraining batch 16 Loss: 0.178387\n",
            "\tTraining batch 17 Loss: 0.312985\n",
            "\tTraining batch 18 Loss: 0.001154\n",
            "Training set: Average loss: 0.249883\n",
            "Validation set: Average loss: 0.354042, Accuracy: 325/366 (89%)\n",
            "\n",
            "Epoch: 81\n",
            "\tTraining batch 1 Loss: 0.320152\n",
            "\tTraining batch 2 Loss: 0.143529\n",
            "\tTraining batch 3 Loss: 0.135124\n",
            "\tTraining batch 4 Loss: 0.271839\n",
            "\tTraining batch 5 Loss: 0.233074\n",
            "\tTraining batch 6 Loss: 0.124603\n",
            "\tTraining batch 7 Loss: 0.437928\n",
            "\tTraining batch 8 Loss: 0.201335\n",
            "\tTraining batch 9 Loss: 0.345267\n",
            "\tTraining batch 10 Loss: 0.212703\n",
            "\tTraining batch 11 Loss: 0.351759\n",
            "\tTraining batch 12 Loss: 0.235214\n",
            "\tTraining batch 13 Loss: 0.166153\n",
            "\tTraining batch 14 Loss: 0.210841\n",
            "\tTraining batch 15 Loss: 0.089315\n",
            "\tTraining batch 16 Loss: 0.289932\n",
            "\tTraining batch 17 Loss: 0.080562\n",
            "\tTraining batch 18 Loss: 0.009980\n",
            "Training set: Average loss: 0.214406\n",
            "Validation set: Average loss: 0.376423, Accuracy: 321/366 (88%)\n",
            "\n",
            "Epoch: 82\n",
            "\tTraining batch 1 Loss: 0.243098\n",
            "\tTraining batch 2 Loss: 0.116364\n",
            "\tTraining batch 3 Loss: 0.067361\n",
            "\tTraining batch 4 Loss: 0.224210\n",
            "\tTraining batch 5 Loss: 0.202264\n",
            "\tTraining batch 6 Loss: 0.260324\n",
            "\tTraining batch 7 Loss: 0.373023\n",
            "\tTraining batch 8 Loss: 0.279350\n",
            "\tTraining batch 9 Loss: 0.336124\n",
            "\tTraining batch 10 Loss: 0.290127\n",
            "\tTraining batch 11 Loss: 0.194682\n",
            "\tTraining batch 12 Loss: 0.182112\n",
            "\tTraining batch 13 Loss: 0.240203\n",
            "\tTraining batch 14 Loss: 0.318658\n",
            "\tTraining batch 15 Loss: 0.259386\n",
            "\tTraining batch 16 Loss: 0.146841\n",
            "\tTraining batch 17 Loss: 0.264937\n",
            "\tTraining batch 18 Loss: 0.085558\n",
            "Training set: Average loss: 0.226923\n",
            "Validation set: Average loss: 0.410934, Accuracy: 323/366 (88%)\n",
            "\n",
            "Epoch: 83\n",
            "\tTraining batch 1 Loss: 0.357433\n",
            "\tTraining batch 2 Loss: 0.311074\n",
            "\tTraining batch 3 Loss: 0.114122\n",
            "\tTraining batch 4 Loss: 0.160796\n",
            "\tTraining batch 5 Loss: 0.337972\n",
            "\tTraining batch 6 Loss: 0.159710\n",
            "\tTraining batch 7 Loss: 0.145770\n",
            "\tTraining batch 8 Loss: 0.256260\n",
            "\tTraining batch 9 Loss: 0.287428\n",
            "\tTraining batch 10 Loss: 0.259049\n",
            "\tTraining batch 11 Loss: 0.460038\n",
            "\tTraining batch 12 Loss: 0.177696\n",
            "\tTraining batch 13 Loss: 0.274579\n",
            "\tTraining batch 14 Loss: 0.167195\n",
            "\tTraining batch 15 Loss: 0.211090\n",
            "\tTraining batch 16 Loss: 0.383408\n",
            "\tTraining batch 17 Loss: 0.172164\n",
            "\tTraining batch 18 Loss: 0.833337\n",
            "Training set: Average loss: 0.281618\n",
            "Validation set: Average loss: 0.343060, Accuracy: 332/366 (91%)\n",
            "\n",
            "Epoch: 84\n",
            "\tTraining batch 1 Loss: 0.078563\n",
            "\tTraining batch 2 Loss: 0.403010\n",
            "\tTraining batch 3 Loss: 0.381306\n",
            "\tTraining batch 4 Loss: 0.736174\n",
            "\tTraining batch 5 Loss: 0.361729\n",
            "\tTraining batch 6 Loss: 0.497402\n",
            "\tTraining batch 7 Loss: 0.599003\n",
            "\tTraining batch 8 Loss: 0.317984\n",
            "\tTraining batch 9 Loss: 0.536140\n",
            "\tTraining batch 10 Loss: 0.507677\n",
            "\tTraining batch 11 Loss: 1.040878\n",
            "\tTraining batch 12 Loss: 0.428272\n",
            "\tTraining batch 13 Loss: 0.386084\n",
            "\tTraining batch 14 Loss: 0.169051\n",
            "\tTraining batch 15 Loss: 0.259428\n",
            "\tTraining batch 16 Loss: 0.496078\n",
            "\tTraining batch 17 Loss: 0.555473\n",
            "\tTraining batch 18 Loss: 0.494963\n",
            "Training set: Average loss: 0.458290\n",
            "Validation set: Average loss: 0.402170, Accuracy: 314/366 (86%)\n",
            "\n",
            "Epoch: 85\n",
            "\tTraining batch 1 Loss: 0.433623\n",
            "\tTraining batch 2 Loss: 0.375996\n",
            "\tTraining batch 3 Loss: 0.245593\n",
            "\tTraining batch 4 Loss: 0.416786\n",
            "\tTraining batch 5 Loss: 0.447626\n",
            "\tTraining batch 6 Loss: 0.324001\n",
            "\tTraining batch 7 Loss: 0.349292\n",
            "\tTraining batch 8 Loss: 0.279823\n",
            "\tTraining batch 9 Loss: 0.314749\n",
            "\tTraining batch 10 Loss: 0.301618\n",
            "\tTraining batch 11 Loss: 0.629096\n",
            "\tTraining batch 12 Loss: 0.242713\n",
            "\tTraining batch 13 Loss: 0.372443\n",
            "\tTraining batch 14 Loss: 0.249664\n",
            "\tTraining batch 15 Loss: 0.279247\n",
            "\tTraining batch 16 Loss: 0.291110\n",
            "\tTraining batch 17 Loss: 0.213355\n",
            "\tTraining batch 18 Loss: 0.381583\n",
            "Training set: Average loss: 0.341573\n",
            "Validation set: Average loss: 0.396243, Accuracy: 313/366 (86%)\n",
            "\n",
            "Epoch: 86\n",
            "\tTraining batch 1 Loss: 0.542633\n",
            "\tTraining batch 2 Loss: 0.334828\n",
            "\tTraining batch 3 Loss: 0.122114\n",
            "\tTraining batch 4 Loss: 0.338284\n",
            "\tTraining batch 5 Loss: 0.326748\n",
            "\tTraining batch 6 Loss: 0.268263\n",
            "\tTraining batch 7 Loss: 0.321875\n",
            "\tTraining batch 8 Loss: 0.210709\n",
            "\tTraining batch 9 Loss: 0.582643\n",
            "\tTraining batch 10 Loss: 0.260183\n",
            "\tTraining batch 11 Loss: 0.346705\n",
            "\tTraining batch 12 Loss: 0.188601\n",
            "\tTraining batch 13 Loss: 0.329220\n",
            "\tTraining batch 14 Loss: 0.261776\n",
            "\tTraining batch 15 Loss: 0.375641\n",
            "\tTraining batch 16 Loss: 0.428585\n",
            "\tTraining batch 17 Loss: 0.099721\n",
            "\tTraining batch 18 Loss: 0.019776\n",
            "Training set: Average loss: 0.297683\n",
            "Validation set: Average loss: 0.426382, Accuracy: 322/366 (88%)\n",
            "\n",
            "Epoch: 87\n",
            "\tTraining batch 1 Loss: 0.411650\n",
            "\tTraining batch 2 Loss: 0.239087\n",
            "\tTraining batch 3 Loss: 0.141581\n",
            "\tTraining batch 4 Loss: 0.218423\n",
            "\tTraining batch 5 Loss: 0.514764\n",
            "\tTraining batch 6 Loss: 0.336072\n",
            "\tTraining batch 7 Loss: 0.273623\n",
            "\tTraining batch 8 Loss: 0.243702\n",
            "\tTraining batch 9 Loss: 0.334952\n",
            "\tTraining batch 10 Loss: 0.385718\n",
            "\tTraining batch 11 Loss: 0.431301\n",
            "\tTraining batch 12 Loss: 0.258568\n",
            "\tTraining batch 13 Loss: 0.212366\n",
            "\tTraining batch 14 Loss: 0.507572\n",
            "\tTraining batch 15 Loss: 0.232429\n",
            "\tTraining batch 16 Loss: 0.244474\n",
            "\tTraining batch 17 Loss: 0.229705\n",
            "\tTraining batch 18 Loss: 0.012324\n",
            "Training set: Average loss: 0.290462\n",
            "Validation set: Average loss: 0.332792, Accuracy: 326/366 (89%)\n",
            "\n",
            "Epoch: 88\n",
            "\tTraining batch 1 Loss: 0.258634\n",
            "\tTraining batch 2 Loss: 0.119168\n",
            "\tTraining batch 3 Loss: 0.162480\n",
            "\tTraining batch 4 Loss: 0.299022\n",
            "\tTraining batch 5 Loss: 0.350046\n",
            "\tTraining batch 6 Loss: 0.217882\n",
            "\tTraining batch 7 Loss: 0.158324\n",
            "\tTraining batch 8 Loss: 0.285152\n",
            "\tTraining batch 9 Loss: 0.504161\n",
            "\tTraining batch 10 Loss: 0.335574\n",
            "\tTraining batch 11 Loss: 0.182168\n",
            "\tTraining batch 12 Loss: 0.335389\n",
            "\tTraining batch 13 Loss: 0.299046\n",
            "\tTraining batch 14 Loss: 0.188083\n",
            "\tTraining batch 15 Loss: 0.231332\n",
            "\tTraining batch 16 Loss: 0.271131\n",
            "\tTraining batch 17 Loss: 0.200328\n",
            "\tTraining batch 18 Loss: 0.048133\n",
            "Training set: Average loss: 0.247003\n",
            "Validation set: Average loss: 0.422068, Accuracy: 318/366 (87%)\n",
            "\n",
            "Epoch: 89\n",
            "\tTraining batch 1 Loss: 0.362364\n",
            "\tTraining batch 2 Loss: 0.172152\n",
            "\tTraining batch 3 Loss: 0.120139\n",
            "\tTraining batch 4 Loss: 0.277557\n",
            "\tTraining batch 5 Loss: 0.213093\n",
            "\tTraining batch 6 Loss: 0.248186\n",
            "\tTraining batch 7 Loss: 0.254384\n",
            "\tTraining batch 8 Loss: 0.375007\n",
            "\tTraining batch 9 Loss: 0.433923\n",
            "\tTraining batch 10 Loss: 0.242194\n",
            "\tTraining batch 11 Loss: 0.315547\n",
            "\tTraining batch 12 Loss: 0.306635\n",
            "\tTraining batch 13 Loss: 0.215962\n",
            "\tTraining batch 14 Loss: 0.312887\n",
            "\tTraining batch 15 Loss: 0.148184\n",
            "\tTraining batch 16 Loss: 0.272015\n",
            "\tTraining batch 17 Loss: 0.175261\n",
            "\tTraining batch 18 Loss: 0.028674\n",
            "Training set: Average loss: 0.248565\n",
            "Validation set: Average loss: 0.347370, Accuracy: 333/366 (91%)\n",
            "\n",
            "Epoch: 90\n",
            "\tTraining batch 1 Loss: 0.354567\n",
            "\tTraining batch 2 Loss: 0.218231\n",
            "\tTraining batch 3 Loss: 0.082068\n",
            "\tTraining batch 4 Loss: 0.358285\n",
            "\tTraining batch 5 Loss: 0.265220\n",
            "\tTraining batch 6 Loss: 0.206197\n",
            "\tTraining batch 7 Loss: 0.205139\n",
            "\tTraining batch 8 Loss: 0.207483\n",
            "\tTraining batch 9 Loss: 0.524129\n",
            "\tTraining batch 10 Loss: 0.351567\n",
            "\tTraining batch 11 Loss: 0.363794\n",
            "\tTraining batch 12 Loss: 0.188318\n",
            "\tTraining batch 13 Loss: 0.324291\n",
            "\tTraining batch 14 Loss: 0.240774\n",
            "\tTraining batch 15 Loss: 0.183589\n",
            "\tTraining batch 16 Loss: 0.318171\n",
            "\tTraining batch 17 Loss: 0.249502\n",
            "\tTraining batch 18 Loss: 0.002262\n",
            "Training set: Average loss: 0.257977\n",
            "Validation set: Average loss: 0.403342, Accuracy: 332/366 (91%)\n",
            "\n",
            "Epoch: 91\n",
            "\tTraining batch 1 Loss: 0.085299\n",
            "\tTraining batch 2 Loss: 0.126533\n",
            "\tTraining batch 3 Loss: 0.200385\n",
            "\tTraining batch 4 Loss: 0.300107\n",
            "\tTraining batch 5 Loss: 0.454235\n",
            "\tTraining batch 6 Loss: 0.261451\n",
            "\tTraining batch 7 Loss: 0.049966\n",
            "\tTraining batch 8 Loss: 0.209843\n",
            "\tTraining batch 9 Loss: 0.356209\n",
            "\tTraining batch 10 Loss: 0.138345\n",
            "\tTraining batch 11 Loss: 0.309362\n",
            "\tTraining batch 12 Loss: 0.362254\n",
            "\tTraining batch 13 Loss: 0.149161\n",
            "\tTraining batch 14 Loss: 0.440221\n",
            "\tTraining batch 15 Loss: 0.244105\n",
            "\tTraining batch 16 Loss: 0.246562\n",
            "\tTraining batch 17 Loss: 0.239604\n",
            "\tTraining batch 18 Loss: 0.000649\n",
            "Training set: Average loss: 0.231905\n",
            "Validation set: Average loss: 0.347181, Accuracy: 328/366 (90%)\n",
            "\n",
            "Epoch: 92\n",
            "\tTraining batch 1 Loss: 0.192968\n",
            "\tTraining batch 2 Loss: 0.140423\n",
            "\tTraining batch 3 Loss: 0.048722\n",
            "\tTraining batch 4 Loss: 0.323981\n",
            "\tTraining batch 5 Loss: 0.439479\n",
            "\tTraining batch 6 Loss: 0.200928\n",
            "\tTraining batch 7 Loss: 0.075628\n",
            "\tTraining batch 8 Loss: 0.295309\n",
            "\tTraining batch 9 Loss: 0.342307\n",
            "\tTraining batch 10 Loss: 0.217051\n",
            "\tTraining batch 11 Loss: 0.200600\n",
            "\tTraining batch 12 Loss: 0.171501\n",
            "\tTraining batch 13 Loss: 0.101155\n",
            "\tTraining batch 14 Loss: 0.206762\n",
            "\tTraining batch 15 Loss: 0.248542\n",
            "\tTraining batch 16 Loss: 0.109624\n",
            "\tTraining batch 17 Loss: 0.248666\n",
            "\tTraining batch 18 Loss: 0.000291\n",
            "Training set: Average loss: 0.197997\n",
            "Validation set: Average loss: 0.431464, Accuracy: 335/366 (92%)\n",
            "\n",
            "Epoch: 93\n",
            "\tTraining batch 1 Loss: 0.283693\n",
            "\tTraining batch 2 Loss: 0.229852\n",
            "\tTraining batch 3 Loss: 0.098728\n",
            "\tTraining batch 4 Loss: 0.196075\n",
            "\tTraining batch 5 Loss: 0.357764\n",
            "\tTraining batch 6 Loss: 0.164091\n",
            "\tTraining batch 7 Loss: 0.384341\n",
            "\tTraining batch 8 Loss: 0.147127\n",
            "\tTraining batch 9 Loss: 0.234727\n",
            "\tTraining batch 10 Loss: 0.193953\n",
            "\tTraining batch 11 Loss: 0.277017\n",
            "\tTraining batch 12 Loss: 0.108044\n",
            "\tTraining batch 13 Loss: 0.426173\n",
            "\tTraining batch 14 Loss: 0.173195\n",
            "\tTraining batch 15 Loss: 0.133283\n",
            "\tTraining batch 16 Loss: 0.283111\n",
            "\tTraining batch 17 Loss: 0.154087\n",
            "\tTraining batch 18 Loss: 0.126556\n",
            "Training set: Average loss: 0.220656\n",
            "Validation set: Average loss: 0.320381, Accuracy: 330/366 (90%)\n",
            "\n",
            "Epoch: 94\n",
            "\tTraining batch 1 Loss: 0.209421\n",
            "\tTraining batch 2 Loss: 0.419477\n",
            "\tTraining batch 3 Loss: 0.102882\n",
            "\tTraining batch 4 Loss: 0.120794\n",
            "\tTraining batch 5 Loss: 0.147754\n",
            "\tTraining batch 6 Loss: 0.137500\n",
            "\tTraining batch 7 Loss: 0.226707\n",
            "\tTraining batch 8 Loss: 0.228861\n",
            "\tTraining batch 9 Loss: 0.208398\n",
            "\tTraining batch 10 Loss: 0.309308\n",
            "\tTraining batch 11 Loss: 0.430098\n",
            "\tTraining batch 12 Loss: 0.091283\n",
            "\tTraining batch 13 Loss: 0.214165\n",
            "\tTraining batch 14 Loss: 0.261074\n",
            "\tTraining batch 15 Loss: 0.303804\n",
            "\tTraining batch 16 Loss: 0.183383\n",
            "\tTraining batch 17 Loss: 0.259651\n",
            "\tTraining batch 18 Loss: 0.000226\n",
            "Training set: Average loss: 0.214155\n",
            "Validation set: Average loss: 0.568744, Accuracy: 328/366 (90%)\n",
            "\n",
            "Epoch: 95\n",
            "\tTraining batch 1 Loss: 0.283165\n",
            "\tTraining batch 2 Loss: 0.323157\n",
            "\tTraining batch 3 Loss: 0.203763\n",
            "\tTraining batch 4 Loss: 0.302586\n",
            "\tTraining batch 5 Loss: 0.228619\n",
            "\tTraining batch 6 Loss: 0.450741\n",
            "\tTraining batch 7 Loss: 0.266542\n",
            "\tTraining batch 8 Loss: 0.225962\n",
            "\tTraining batch 9 Loss: 0.413553\n",
            "\tTraining batch 10 Loss: 0.260907\n",
            "\tTraining batch 11 Loss: 0.358527\n",
            "\tTraining batch 12 Loss: 0.280570\n",
            "\tTraining batch 13 Loss: 0.733248\n",
            "\tTraining batch 14 Loss: 0.185282\n",
            "\tTraining batch 15 Loss: 0.419050\n",
            "\tTraining batch 16 Loss: 0.384729\n",
            "\tTraining batch 17 Loss: 0.322340\n",
            "\tTraining batch 18 Loss: 0.171486\n",
            "Training set: Average loss: 0.323013\n",
            "Validation set: Average loss: 0.331776, Accuracy: 325/366 (89%)\n",
            "\n",
            "Epoch: 96\n",
            "\tTraining batch 1 Loss: 0.393229\n",
            "\tTraining batch 2 Loss: 0.286351\n",
            "\tTraining batch 3 Loss: 0.118363\n",
            "\tTraining batch 4 Loss: 0.324263\n",
            "\tTraining batch 5 Loss: 0.228957\n",
            "\tTraining batch 6 Loss: 0.208122\n",
            "\tTraining batch 7 Loss: 0.212120\n",
            "\tTraining batch 8 Loss: 0.188934\n",
            "\tTraining batch 9 Loss: 0.385169\n",
            "\tTraining batch 10 Loss: 0.243079\n",
            "\tTraining batch 11 Loss: 0.292639\n",
            "\tTraining batch 12 Loss: 0.253160\n",
            "\tTraining batch 13 Loss: 0.275860\n",
            "\tTraining batch 14 Loss: 0.362211\n",
            "\tTraining batch 15 Loss: 0.378301\n",
            "\tTraining batch 16 Loss: 0.295411\n",
            "\tTraining batch 17 Loss: 0.175796\n",
            "\tTraining batch 18 Loss: 0.000354\n",
            "Training set: Average loss: 0.256795\n",
            "Validation set: Average loss: 0.420329, Accuracy: 323/366 (88%)\n",
            "\n",
            "Epoch: 97\n",
            "\tTraining batch 1 Loss: 0.306803\n",
            "\tTraining batch 2 Loss: 0.327242\n",
            "\tTraining batch 3 Loss: 0.097586\n",
            "\tTraining batch 4 Loss: 0.245954\n",
            "\tTraining batch 5 Loss: 0.184903\n",
            "\tTraining batch 6 Loss: 0.206165\n",
            "\tTraining batch 7 Loss: 0.148033\n",
            "\tTraining batch 8 Loss: 0.371787\n",
            "\tTraining batch 9 Loss: 0.321296\n",
            "\tTraining batch 10 Loss: 0.152636\n",
            "\tTraining batch 11 Loss: 0.189144\n",
            "\tTraining batch 12 Loss: 0.178403\n",
            "\tTraining batch 13 Loss: 0.108415\n",
            "\tTraining batch 14 Loss: 0.295425\n",
            "\tTraining batch 15 Loss: 0.428493\n",
            "\tTraining batch 16 Loss: 0.387405\n",
            "\tTraining batch 17 Loss: 0.340398\n",
            "\tTraining batch 18 Loss: 0.009224\n",
            "Training set: Average loss: 0.238851\n",
            "Validation set: Average loss: 0.422206, Accuracy: 330/366 (90%)\n",
            "\n",
            "Epoch: 98\n",
            "\tTraining batch 1 Loss: 0.252869\n",
            "\tTraining batch 2 Loss: 0.320464\n",
            "\tTraining batch 3 Loss: 0.087537\n",
            "\tTraining batch 4 Loss: 0.222933\n",
            "\tTraining batch 5 Loss: 0.402041\n",
            "\tTraining batch 6 Loss: 0.253466\n",
            "\tTraining batch 7 Loss: 0.202995\n",
            "\tTraining batch 8 Loss: 0.220477\n",
            "\tTraining batch 9 Loss: 0.348035\n",
            "\tTraining batch 10 Loss: 0.378990\n",
            "\tTraining batch 11 Loss: 0.209052\n",
            "\tTraining batch 12 Loss: 0.065739\n",
            "\tTraining batch 13 Loss: 0.168554\n",
            "\tTraining batch 14 Loss: 0.247304\n",
            "\tTraining batch 15 Loss: 0.202259\n",
            "\tTraining batch 16 Loss: 0.153266\n",
            "\tTraining batch 17 Loss: 0.229743\n",
            "\tTraining batch 18 Loss: 0.000024\n",
            "Training set: Average loss: 0.220319\n",
            "Validation set: Average loss: 0.369251, Accuracy: 334/366 (91%)\n",
            "\n",
            "Epoch: 99\n",
            "\tTraining batch 1 Loss: 0.159106\n",
            "\tTraining batch 2 Loss: 0.199995\n",
            "\tTraining batch 3 Loss: 0.162790\n",
            "\tTraining batch 4 Loss: 0.223066\n",
            "\tTraining batch 5 Loss: 0.360233\n",
            "\tTraining batch 6 Loss: 0.219241\n",
            "\tTraining batch 7 Loss: 0.332105\n",
            "\tTraining batch 8 Loss: 0.150929\n",
            "\tTraining batch 9 Loss: 0.265213\n",
            "\tTraining batch 10 Loss: 0.170835\n",
            "\tTraining batch 11 Loss: 0.420802\n",
            "\tTraining batch 12 Loss: 0.233577\n",
            "\tTraining batch 13 Loss: 0.210375\n",
            "\tTraining batch 14 Loss: 0.144398\n",
            "\tTraining batch 15 Loss: 0.230140\n",
            "\tTraining batch 16 Loss: 0.168065\n",
            "\tTraining batch 17 Loss: 0.120641\n",
            "\tTraining batch 18 Loss: 0.134341\n",
            "Training set: Average loss: 0.216992\n",
            "Validation set: Average loss: 0.445828, Accuracy: 333/366 (91%)\n",
            "\n",
            "Epoch: 100\n",
            "\tTraining batch 1 Loss: 0.342820\n",
            "\tTraining batch 2 Loss: 0.241186\n",
            "\tTraining batch 3 Loss: 0.188600\n",
            "\tTraining batch 4 Loss: 0.474271\n",
            "\tTraining batch 5 Loss: 0.294239\n",
            "\tTraining batch 6 Loss: 0.248864\n",
            "\tTraining batch 7 Loss: 0.112092\n",
            "\tTraining batch 8 Loss: 0.285180\n",
            "\tTraining batch 9 Loss: 0.369188\n",
            "\tTraining batch 10 Loss: 0.166204\n",
            "\tTraining batch 11 Loss: 0.151105\n",
            "\tTraining batch 12 Loss: 0.126760\n",
            "\tTraining batch 13 Loss: 0.352225\n",
            "\tTraining batch 14 Loss: 0.130284\n",
            "\tTraining batch 15 Loss: 0.205260\n",
            "\tTraining batch 16 Loss: 0.319764\n",
            "\tTraining batch 17 Loss: 0.120933\n",
            "\tTraining batch 18 Loss: 0.084673\n",
            "Training set: Average loss: 0.234092\n",
            "Validation set: Average loss: 0.402710, Accuracy: 332/366 (91%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Specify the loss criteria\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Track metrics in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 10 epochs (We restrict to 10 for time issues)\n",
        "epochs = 100\n",
        "print('Training on', device)\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
        "        test_loss = test(model, device, test_loader)\n",
        "        epoch_nums.append(epoch)\n",
        "        training_loss.append(train_loss)\n",
        "        validation_loss.append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "NedsJbu4VFm5",
        "outputId": "32549c8d-f74d-4751-a4c9-d2df91a06254"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.plot(epoch_nums, training_loss)\n",
        "plt.plot(epoch_nums, validation_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "6-Sj1o2YVL1w",
        "outputId": "48af1971-48bd-43f4-d80f-690429fbd8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions from test set...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Shape of passed values is (4, 4), indices imply (5, 5)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-13a58da094f9>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtick_marks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    756\u001b[0m                 )\n\u001b[1;32m    757\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    759\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    335\u001b[0m     )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (4, 4), indices imply (5, 5)"
          ]
        }
      ],
      "source": [
        "truelabels = []\n",
        "predictions = []\n",
        "model.eval()\n",
        "print(\"Getting predictions from test set...\")\n",
        "for data, target in test_loader:\n",
        "    for label in target.data.numpy():\n",
        "        truelabels.append(label)\n",
        "    for prediction in model(data).data.numpy().argmax(1):\n",
        "        predictions.append(prediction)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(truelabels, predictions)\n",
        "tick_marks = np.arange(len(classes))\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index = classes, columns = classes)\n",
        "plt.figure(figsize = (7,7))\n",
        "sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')\n",
        "plt.xlabel(\"Predicted Shape\", fontsize = 20)\n",
        "plt.ylabel(\"True Shape\", fontsize = 20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQpTAc9bM6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92531991-28d6-49ff-92f6-3d11d24cc972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set: Average loss: 0.387423, Accuracy: 335/366 (92%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new=test(model,device,test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dV2I9oL9uKrKRcuHV3scSrHh8VBRgRY_",
      "authorship_tag": "ABX9TyOFofVjQcmj3e6Z2gNS9R0I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}